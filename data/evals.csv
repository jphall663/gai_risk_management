Task,Attribute,Evaluation Framework/Benchmark/Paper,Testing Approach
Natural Language Understanding,Text classification,"HELM
Miscellaneous text classification",Benchmarking
Natural Language Understanding,Text classification,"Big-bench
Emotional understanding
Intent recognition
Humor",Benchmarking
Natural Language Understanding,Text classification,"Hugging Face
Text classification
Token classification
Zero-shot classification",Benchmarking
Natural Language Understanding,Sentiment analysis,"HELM
Sentiment analysis",Benchmarking
Natural Language Understanding,Sentiment analysis,"Evaluation Harness
GLUE",Benchmarking
Natural Language Understanding,Sentiment analysis,"Big-bench
Emotional understanding",Benchmarking
Natural Language Understanding,Toxicity detection,"HELM
Toxicity detection",Benchmarking
Natural Language Understanding,Toxicity detection,"Evaluation Harness
ToxiGen",Benchmarking
Natural Language Understanding,Toxicity detection,"Big-bench
Toxicity",Benchmarking
Natural Language Understanding,Information retrieval,"HELM
Information retrieval",Benchmarking
Natural Language Understanding,Sufficient information,"Big-bench
Sufficient information",Benchmarking
Natural Language Understanding,Sufficient information,"FLASK
Metacognition",Benchmarking (with human and model scoring)
Natural Language Understanding,Natural language inference,"Big-bench
Analytic entailment (specific task)
Formal fallacies and syllogisms with negation (specific task)
Entailed polarity (specific task)",Benchmarking
Natural Language Understanding,Natural language inference,"Evaluation Harness
GLUE",Benchmarking
Natural Language Understanding,General English understanding,"HELM
Language",Benchmarking
Natural Language Understanding,General English understanding,"Big-bench
Morphology
Grammar
Syntax",Benchmarking
Natural Language Understanding,General English understanding,"Evaluation Harness
BLiMP",Benchmarking
Natural Language Understanding,General English understanding,"Eval Gauntlet
Language Understanding",Benchmarking
Natural Language Generation,Summarization,"HELM
Summarization",Benchmarking
Natural Language Generation,Summarization,"Big-bench
Summarization",Benchmarking
Natural Language Generation,Summarization,"Evaluation Harness
BLiMP",Benchmarking
Natural Language Generation,Summarization,"Hugging Face
Summarization",Benchmarking
Natural Language Generation,Question generation and answering,"HELM
Question answering",Benchmarking
Natural Language Generation,Question generation and answering,"Big-bench
Contextual question answering
Reading comprehension
Question generation",Benchmarking
Natural Language Generation,Question generation and answering,"Evaluation Harness
CoQA
ARC",Benchmarking
Natural Language Generation,Question generation and answering,"FLASK
Logical correctness
Logical robustness
Logical efficiency
Comprehension
Completeness",Benchmarking (with human and model scoring)
Natural Language Generation,Question generation and answering,"Hugging Face
Question answering",Benchmarking
Natural Language Generation,Question generation and answering,"Eval Gauntlet
Reading comprehension",Benchmarking
Natural Language Generation,Conversations and dialogue,MT-bench,Benchmarking (with human and model scoring)
Natural Language Generation,Conversations and dialogue,"Evaluation Harness
MuTual",Benchmarking
Natural Language Generation,Conversations and dialogue,"Hugging Face
Conversational",Benchmarking
Natural Language Generation,Paraphrasing,"Big-bench
Paraphrase",Benchmarking
Natural Language Generation,Other response qualities,"FLASK
Readability
Conciseness
Insightfulness",Benchmarking (with human and model scoring)
Natural Language Generation,Other response qualities,"Big-bench
Creativity",Benchmarking
Natural Language Generation,Other response qualities,Putting GPT-3's Creativity to the (Alternative Uses) Test,Benchmarking (with human scoring)
Natural Language Generation,Miscellaneous text generation,"Hugging Face
Fill-mask
Text generation",Benchmarking
Reasoning,Reasoning,"HELM
Reasoning",Benchmarking
Reasoning,Reasoning,"Big-bench
Algorithms
Logical reasoning
Implicit reasoning
Mathematics
Arithmetic
Algebra
Mathematical proof
Fallacy
Negation
Computer code
Probabilistic reasoning
Social reasoning
Analogical reasoning
Multi-step
Understanding the World",Benchmarking
Reasoning,Reasoning,"Evaluation Harness
PIQA, PROST - Physical reasoning
MC-TACO - Temporal reasoning
MathQA - Mathematical reasoning
LogiQA - Logical reasoning
SAT Analogy Questions - Similarity of semantic relations
DROP, MuTual â€“ Multi-step reasoning",Benchmarking
Reasoning,Reasoning,"Eval Gauntlet
Commonsense reasoning
Symbolic problem solving
Programming",Benchmarking
Knowledge and factuality,Knowledge and factuality,"HELM
Knowledge",Benchmarking
Knowledge and factuality,Knowledge and factuality,"Big-bench
Context Free Question Answering",Benchmarking
Knowledge and factuality,Knowledge and factuality,"Evaluation Harness
HellaSwag, OpenBookQA - General commonsense knowledge
TruthfulQA - Factuality of knowledge",Benchmarking
Knowledge and factuality,Knowledge and factuality,"FLASK
Background Knowledge",Benchmarking (with human and model scoring)
Knowledge and factuality,Knowledge and factuality,"Eval Gauntlet
World Knowledge",Benchmarking
Effectiveness of tool use,Effectiveness of tool use,HuggingGPT,Benchmarking (with human and model scoring)
Effectiveness of tool use,Effectiveness of tool use,TALM,Benchmarking
Effectiveness of tool use,Effectiveness of tool use,Toolformer,Benchmarking (with human scoring)
Effectiveness of tool use,Effectiveness of tool use,ToolLLM,Benchmarking (with model scoring)
Multilingualism,Multilingualism,"Big-bench
Low-resource language
Non-English
Translation",Benchmarking
Multilingualism,Multilingualism,"Evaluation Harness
C-Eval (Chinese evaluation suite)
MGSM
Translation",Benchmarking
Multilingualism,Multilingualism,BELEBELE,Benchmarking
Multilingualism,Multilingualism,MASSIVE,Benchmarking
Multilingualism,Multilingualism,"HELM
Language (Twitter AAE)",Benchmarking
Multilingualism,Multilingualism,"Eval Gauntlet
Language Understanding",Benchmarking
Context length,Context length,"Big-bench
Context length",Benchmarking
Context length,Context length,"Evaluation Harness
SCROLLS",Benchmarking
Law,Law,LegalBench,Benchmarking (with algorithmic and human scoring)
Medicine,Medicine,Large Language Models Encode Clinical Knowledge,Benchmarking (with human scoring)
Medicine,Medicine,Towards Generalist Biomedical AI,Benchmarking (with human scoring)
Finance,Finance,BloombergGPT,Benchmarking
Toxicity generation,Toxicity generation,"HELM
Toxicity",Benchmarking
Toxicity generation,Toxicity generation,"DecodingTrust
Toxicity",Benchmarking
Toxicity generation,Toxicity generation,Red Teaming Language Models with Language Models,Automated Red Teaming
Bias,Demographical representation,HELM,Benchmarking
Bias,Demographical representation,Finding New Biases in Language Models with a Holistic Descriptor Dataset,Benchmarking
Bias,Stereotype bias,"HELM
Bias",Benchmarking
Bias,Stereotype bias,"DecodingTrust
Stereotype Bias",Benchmarking
Bias,Stereotype bias,"Big-bench
Social bias
Racial bias
Gender bias
Religious bias",Benchmarking
Bias,Stereotype bias,"Evaluation Harness
CrowS-Pairs",Benchmarking
Bias,Fairness,"DecodingTrust
Fairness",Benchmarking
Bias,Distributional bias,Red Teaming Language Models with Language Models,Automated Red Teaming
Bias,Representation of subjective opinions,Towards Measuring the Representation of Subjective Global Opinions in Language Models,Benchmarking
Bias,Political bias,From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models,Benchmarking
Bias,Political bias,The Self-Perception and Political Biases of ChatGPT,Benchmarking
Bias,Capability fairness,"HELM
Language (Twitter AAE)",Benchmarking
Machine ethics,Machine ethics,"DecodingTrust
Machine Ethics",Benchmarking
Machine ethics,Machine ethics,"Evaluation Harness
ETHICS",Benchmarking
Psychological traits,Psychological traits,Does GPT-3 Demonstrate Psychopathy?,Benchmarking
Psychological traits,Psychological traits,Estimating the Personality of White-Box Language Models,Benchmarking
Psychological traits,Psychological traits,The Self-Perception and Political Biases of ChatGPT,Benchmarking
Robustness,Robustness,"HELM
Robustness to contrast sets",Benchmarking
Robustness,Robustness,"DecodingTrust
Out-of-Distribution Robustness
Adversarial Robustness
Robustness Against Adversarial Demonstrations",Benchmarking
Robustness,Robustness,"Big-bench
Out-of-Distribution Robustness",Benchmarking
Robustness,Robustness,Susceptibility to Influence of Large Language Models,Benchmarking
Data governance,Data governance,"DecodingTrust
Privacy",Benchmarking
Data governance,Data governance,"HELM
Memorization and copyright",Benchmarking
Data governance,Data governance,Red Teaming Language Models with Language Models,Automated Red Teaming
Data governance,Data governance,An Evaluation on Large Language Model Outputs: Discourse and Memorization,Benchmarking (with human scoring)
Dangerous Capabilities,Self and situation awareness,"Big-bench
Self-Awareness",Benchmarking
Dangerous Capabilities,Persuasion and manipulation,"HELM
Narrative Reiteration
Narrative Wedging",Benchmarking (with human scoring)
Dangerous Capabilities,Persuasion and manipulation,"Big-bench
Convince Me (specific task)",Benchmarking
Dangerous Capabilities,Misinformation,"HELM
Question answering
Summarization",Benchmarking
Dangerous Capabilities,Misinformation,"Big-bench
Truthfulness",Benchmarking
Dangerous Capabilities,Disinformation,"HELM
Narrative Reiteration
Narrative Wedging",Benchmarking (with human scoring)
Dangerous Capabilities,Disinformation,"Big-bench
Convince Me (specific task)",Benchmarking
