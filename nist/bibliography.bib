@article{airmf,
	title={Artificial {I}ntelligence {R}isk {M}anagement {F}ramework ({AI RMF} 1.0)},
	author={AI, NIST},
	year={2023}
}

% ---------- Risk Tiers ---------- 

@ARTICLE{ieee1012,
  author={},
  journal={IEEE Std 1012-2016 (Revision of IEEE Std 1012-2012/ Incorporates IEEE Std 1012-2016/Cor1-2017)}, 
  title={{IEEE} Standard for System, Software, and Hardware Verification and Validation}, 
  year={2017},
  volume={},
  number={},
  pages={1-260},
  keywords={IEEE Standards;Software testing;Performance evaluation;Product life cycle management;Environmental factors;Hazards;acceptance testing;architecture evaluation;component testing;concept documentation evaluation;criticality;criticality analysis;design evaluation;disposal plan evaluation;environmental verification and validation (V&V) factors;hardware life cycle;hardware V&V;hardware verification and validation;hazard analysis;IEEE 1012;implementation evaluation;independent verification and validation (IV&V);integration testing;integrity level;interface analysis;IV&V;minimum V&V tasks;nth of a kind;objective evidence;operating procedure evaluation;qualification testing;quality assurance;regression analysis;regression testing;requirements allocation analysis;requirements evaluation;reuse software;risk analysis;security analysis;software life cycle;software quality assurance (SQA);software V&V;software verification and validation;source code documentation evaluation;source code evaluation;SQA;stakeholder needs and requirements evaluation;system element interaction analysis;system life cycle;system maintenance strategy assessment;system of interest;system requirements evaluation;system V&V;system verification and validation;testing;traceability analysis;V&V;V&V measures;validation;verification},
  doi={10.1109/IEEESTD.2017.8055462}}

@ARTICLE{nist80030r1,
  author={},
  journal={NIST SP800-03R1}, 
  title={Guide for Conducting Risk Assessments}, 
  year={2012},
  volume={},
  number={},
  pages={i-L2},
  keywords={-,
  doi={10.1109/IEEESTD.2017.8055462}}

% ---------- Evals ---------- 

@article{belebele,
  title={The belebele benchmark: a parallel reading comprehension dataset in 122 language variants},
  author={Bandarkar, Lucas and Liang, Davis and Muller, Benjamin and Artetxe, Mikel and Shukla, Satya Narayan and Husa, Donald and Goyal, Naman and Krishnan, Abhinandan and Zettlemoyer, Luke and Khabsa, Madian},
  journal={arXiv preprint arXiv:2308.16884},
  year={2023}
} %

@article{bigbench,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
} % 

@article{ceval,
  title={C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models},
  author={Huang, Yuzhen and Bai, Yuzhuo and Zhu, Zhihao and Zhang, Junlei and Zhang, Jinghan and Su, Tangjun and Liu, Junteng and Lv, Chuancheng and Zhang, Yikai and Fu, Yao and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
} %

@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
} %

@article{decodingtrust,
  title={DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models},
  author={Wang, Boxin and Chen, Weixin and Pei, Hengzhi and Xie, Chulin and Kang, Mintong and Zhang, Chenhui and Xu, Chejian and Xiong, Zidi and Dutta, Ritik and Schaeffer, Rylan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
} %

@article{detectpretraincode,
  title={Detecting pretraining data from large language models},
  author={Shi, Weijia and Ajith, Anirudh and Xia, Mengzhou and Huang, Yangsibo and Liu, Daogao and Blevins, Terra and Chen, Danqi and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2310.16789},
  year={2023}
} %

@article{de2023evaluation,
  title={An evaluation on large language model outputs: Discourse and memorization},
  author={de Wynter, Adrian and Wang, Xun and Sokolov, Alex and Gu, Qilong and Chen, Si-Qing},
  journal={Natural Language Processing Journal},
  volume={4},
  pages={100024},
  year={2023},
  publisher={Elsevier}
} %

@article{durmus2023towards,
  title={Towards measuring the representation of subjective global opinions in language models},
  author={Durmus, Esin and Nyugen, Karina and Liao, Thomas I and Schiefer, Nicholas and Askell, Amanda and Bakhtin, Anton and Chen, Carol and Hatfield-Dodds, Zac and Hernandez, Danny and Joseph, Nicholas and others},
  journal={arXiv preprint arXiv:2306.16388},
  year={2023}
} %

@misc{evalgauntlet,
  author = {Jeremy Dohmann},
  title = {Blazingly Fast LLM Evaluation for In-Context Learning},
  howpublished = {\url{https://www.databricks.com/blog/llm-evaluation-for-icl}},
  note = {Last accessed: May 24, 2024}
} %

@misc{evalharness,
  author = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title = {A framework for few-shot language model evaluation},
  month = 12,
  year = 2023,
  publisher = {Zenodo},
  version = {v0.4.0},
  doi = {10.5281/zenodo.10256836},
  url = {https://zenodo.org/records/10256836}
} %

@article{feng2023pretraining,
  title={From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair NLP models},
  author={Feng, Shangbin and Park, Chan Young and Liu, Yuhan and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2305.08283},
  year={2023}
} %

@article{flask,
  title={Flask: Fine-grained language model evaluation based on alignment skill sets},
  author={Ye, Seonghyeon and Kim, Doyoung and Kim, Sungdong and Hwang, Hyeonbin and Kim, Seungone and Jo, Yongrae and Thorne, James and Kim, Juho and Seo, Minjoon},
  journal={arXiv preprint arXiv:2307.10928},
  year={2023}
} %

@inproceedings{huang2023catastrophic,
  title={Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation},
  author={Huang, Yangsibo and Gupta, Samyak and Xia, Mengzhou and Li, Kai and Chen, Danqi},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
} %

@article{helm,
  title={Holistic evaluation of language models},
  author={Bommasani, Rishi and Liang, Percy and Lee, Tony},
  journal={Annals of the New York Academy of Sciences},
  volume={1525},
  number={1},
  pages={140--146},
  year={2023},
  publisher={Wiley Online Library}
} %

@misc{huggingface,
  author = {Hugging Face},
  title = {Evaluation},
  howpublished = {\url{https://huggingface.co/docs/evaluate/index}},
  note = {Last accessed: May 24, 2024}
} %

@article{llmprivacy,
  title={Beyond memorization: Violating privacy via inference with large language models},
  author={Staab, Robin and Vero, Mark and Balunovi{\'c}, Mislav and Vechev, Martin},
  journal={arXiv preprint arXiv:2310.07298},
  year={2023}
} %

@article{markmywords,
  title={Mark my words: Analyzing and evaluating language model watermarks},
  author={Piet, Julien and Sitawarin, Chawin and Fang, Vivian and Mu, Norman and Wagner, David},
  journal={arXiv preprint arXiv:2312.00273},
  year={2023}
} %

@article{massive,
  title={Massive: A 1m-example multilingual natural language understanding dataset with 51 typologically-diverse languages},
  author={FitzGerald, Jack and Hench, Christopher and Peris, Charith and Mackie, Scott and Rottmann, Kay and Sanchez, Ana and Nash, Aaron and Urbach, Liam and Kakarala, Vishesh and Singh, Richa and others},
  journal={arXiv preprint arXiv:2204.08582},
  year={2022}
} %

@article{mehrotra2023tree,
  title={Tree of attacks: Jailbreaking black-box llms automatically},
  author={Mehrotra, Anay and Zampetakis, Manolis and Kassianik, Paul and Nelson, Blaine and Anderson, Hyrum and Singer, Yaron and Karbasi, Amin},
  journal={arXiv preprint arXiv:2312.02119},
  year={2023}
} %

@article{mimir,
  title={Do Membership Inference Attacks Work on Large Language Models?}, 
  author={Michael Duan and Anshuman Suri and Niloofar Mireshghallah and Sewon Min and Weijia Shi and Luke Zettlemoyer and Yulia Tsvetkov and Yejin Choi and David Evans and Hannaneh Hajishirzi},
  year={2024},
  journal={arXiv:2402.07841},
} %

@article{mlcommons,
  title={Introducing v0. 5 of the ai safety benchmark from mlcommons},
  author={Vidgen, Bertie and Agrawal, Adarsh and Ahmed, Ahmed M and Akinwande, Victor and Al-Nuaimi, Namir and Alfaraj, Najla and Alhajjar, Elie and Aroyo, Lora and Bavalatti, Trupti and Blili-Hamelin, Borhane and others},
  journal={arXiv preprint arXiv:2404.12241},
  year={2024}
} %

@article{mtbench,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
} %

@article{rutinowski2023self,
  title={The self-perception and political biases of chatgpt},
  author={Rutinowski, J{\'e}r{\^o}me and Franke, Sven and Endendyk, Jan and Dormuth, Ina and Roidl, Moritz and Pauly, Markus and others},
  journal={Human Behavior and Emerging Technologies},
  volume={2024},
  publisher={Hindawi}
} %

@article{shen2023anything,
  title={"Do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models},
  author={Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
  journal={arXiv preprint arXiv:2308.03825},
  year={2023}
} %

@article{smith2022m,
  title={"I'm sorry to hear that": Finding New Biases in Language Models with a Holistic Descriptor Dataset},
  author={Smith, Eric Michael and Hall, Melissa and Kambadur, Melanie and Presani, Eleonora and Williams, Adina},
  journal={arXiv preprint arXiv:2205.09209},
  year={2022}
} %

@article{wmdp,
  title={The wmdp benchmark: Measuring and reducing malicious use with unlearning},
  author={Li, Nathaniel and Pan, Alexander and Gopal, Anjali and Yue, Summer and Berrios, Daniel and Gatti, Alice and Li, Justin D and Dombrowski, Ann-Kathrin and Goel, Shashwat and Phan, Long and others},
  journal={arXiv preprint arXiv:2403.03218},
  year={2024}
} %