{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ad31e1-1f05-4c9b-a3de-bc21fda68f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# show everything\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ca2f43-89af-4d0e-8552-f4cc3e46099c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accountable and Transparent</th>\n",
       "      <th>Explainable and Interpretable</th>\n",
       "      <th>Fair with Harmful Bias Managed</th>\n",
       "      <th>Privacy Enhanced</th>\n",
       "      <th>Safe</th>\n",
       "      <th>Secure and Resilient</th>\n",
       "      <th>Valid and Reliable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)</td>\n",
       "      <td></td>\n",
       "      <td>BELEBELE</td>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation</td>\n",
       "      <td>Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "      <td>llmprivacy</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations</td>\n",
       "      <td>Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecodingTrust: Machine Ethics</td>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "      <td>mimir</td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td>detect-pretrain-code</td>\n",
       "      <td>Big-bench: Context Free Question Answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evaluation Harness: ETHICS</td>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "      <td></td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>In-The-Wild Jailbreak Prompts on LLMs</td>\n",
       "      <td>Big-bench: Contextual question answering, Reading comprehension, Question generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "      <td></td>\n",
       "      <td>MLCommons</td>\n",
       "      <td>JailbreakingLLMs\\n</td>\n",
       "      <td>Big-bench: Morphology, Grammar, Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LegalBench</td>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "      <td></td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td>llmprivacy</td>\n",
       "      <td>Big-bench: Out-of-Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mark My Words</td>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mimir</td>\n",
       "      <td>Big-bench: Paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack</td>\n",
       "      <td>Big-bench: Sufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet\\nReading comprehension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Bias</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet: Language Understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet: World Knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: BLiMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MASSIVE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: CoQA, ARC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: GLUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: MuTual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FLASK: Readability, Conciseness, Insightfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Text classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Question answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Robustness to contrast sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Fill-mask, Text generation - Benchmarking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Question answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Text classification, Token classification, Zero-shot classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       Accountable and Transparent  \\\n",
       "0   An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)   \n",
       "1                                                                                          Big-bench: Truthfulness   \n",
       "2                                                                                    DecodingTrust: Machine Ethics   \n",
       "3                                                                                       Evaluation Harness: ETHICS   \n",
       "4                                                                                                  HELM: Copyright   \n",
       "5                                                                                                      LegalBench    \n",
       "6                                                                                                    Mark My Words   \n",
       "7                                                                                                                    \n",
       "8                                                                                                                    \n",
       "9                                                                                                                    \n",
       "10                                                                                                                   \n",
       "11                                                                                                                   \n",
       "12                                                                                                                   \n",
       "13                                                                                                                   \n",
       "14                                                                                                                   \n",
       "15                                                                                                                   \n",
       "16                                                                                                                   \n",
       "17                                                                                                                   \n",
       "18                                                                                                                   \n",
       "19                                                                                                                   \n",
       "20                                                                                                                   \n",
       "21                                                                                                                   \n",
       "22                                                                                                                   \n",
       "23                                                                                                                   \n",
       "24                                                                                                                   \n",
       "25                                                                                                                   \n",
       "26                                                                                                                   \n",
       "27                                                                                                                   \n",
       "28                                                                                                                   \n",
       "29                                                                                                                   \n",
       "30                                                                                                                   \n",
       "31                                                                                                                   \n",
       "32                                                                                                                   \n",
       "33                                                                                                                   \n",
       "\n",
       "   Explainable and Interpretable  \\\n",
       "0                                  \n",
       "1                                  \n",
       "2                                  \n",
       "3                                  \n",
       "4                                  \n",
       "5                                  \n",
       "6                                  \n",
       "7                                  \n",
       "8                                  \n",
       "9                                  \n",
       "10                                 \n",
       "11                                 \n",
       "12                                 \n",
       "13                                 \n",
       "14                                 \n",
       "15                                 \n",
       "16                                 \n",
       "17                                 \n",
       "18                                 \n",
       "19                                 \n",
       "20                                 \n",
       "21                                 \n",
       "22                                 \n",
       "23                                 \n",
       "24                                 \n",
       "25                                 \n",
       "26                                 \n",
       "27                                 \n",
       "28                                 \n",
       "29                                 \n",
       "30                                 \n",
       "31                                 \n",
       "32                                 \n",
       "33                                 \n",
       "\n",
       "                                                                                                        Fair with Harmful Bias Managed  \\\n",
       "0                                                                                                                             BELEBELE   \n",
       "1                                                                          Big-bench: Low-resource language, Non-English, Translation    \n",
       "2                                                                     Big-bench: Social bias, Racial bias, Gender bias, Religious bias   \n",
       "3                                                                                                                  Big-bench: Toxicity   \n",
       "4                                                                                                              DecodingTrust: Fairness   \n",
       "5                                                                                                       DecodingTrust: Stereotype Bias   \n",
       "6                                                                                                              DecodingTrust: Toxicity   \n",
       "7                                                                                                    C-Eval (Chinese evaluation suite)   \n",
       "8                                                                                                     Evaluation Harness: CrowS-Pairs    \n",
       "9                                                                                                          Evaluation Harness: ToxiGen   \n",
       "10                                                            Finding New Biases in Language Models with a Holistic Descriptor Dataset   \n",
       "11  From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models   \n",
       "12                                                                                                                          HELM: Bias   \n",
       "13                                                                                                        HELM: Language (Twitter AAE)   \n",
       "14                                                                                                                      HELM: Toxicity   \n",
       "15                                                                                                                             MASSIVE   \n",
       "16                                                                              MT-bench - Benchmarking (with human and model scoring)   \n",
       "17                                                                                 The Self-Perception and Political Biases of ChatGPT   \n",
       "18                                               Towards Measuring the Representation of Subjective Global Opinions in Language Models   \n",
       "19                                                                                                                                       \n",
       "20                                                                                                                                       \n",
       "21                                                                                                                                       \n",
       "22                                                                                                                                       \n",
       "23                                                                                                                                       \n",
       "24                                                                                                                                       \n",
       "25                                                                                                                                       \n",
       "26                                                                                                                                       \n",
       "27                                                                                                                                       \n",
       "28                                                                                                                                       \n",
       "29                                                                                                                                       \n",
       "30                                                                                                                                       \n",
       "31                                                                                                                                       \n",
       "32                                                                                                                                       \n",
       "33                                                                                                                                       \n",
       "\n",
       "   Privacy Enhanced                        Safe  \\\n",
       "0   HELM: Copyright      Big-bench: Convince Me   \n",
       "1        llmprivacy     Big-bench: Truthfulness   \n",
       "2             mimir  HELM: Reiteration, Wedging   \n",
       "3                                 Mark My Words   \n",
       "4                                     MLCommons   \n",
       "5                            The WMDP Benchmark   \n",
       "6                                                 \n",
       "7                                                 \n",
       "8                                                 \n",
       "9                                                 \n",
       "10                                                \n",
       "11                                                \n",
       "12                                                \n",
       "13                                                \n",
       "14                                                \n",
       "15                                                \n",
       "16                                                \n",
       "17                                                \n",
       "18                                                \n",
       "19                                                \n",
       "20                                                \n",
       "21                                                \n",
       "22                                                \n",
       "23                                                \n",
       "24                                                \n",
       "25                                                \n",
       "26                                                \n",
       "27                                                \n",
       "28                                                \n",
       "29                                                \n",
       "30                                                \n",
       "31                                                \n",
       "32                                                \n",
       "33                                                \n",
       "\n",
       "                                                                    Secure and Resilient  \\\n",
       "0                   Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation   \n",
       "1   DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations   \n",
       "2                                                                   detect-pretrain-code   \n",
       "3                                                  In-The-Wild Jailbreak Prompts on LLMs   \n",
       "4                                                                     JailbreakingLLMs\\n   \n",
       "5                                                                             llmprivacy   \n",
       "6                                                                                  mimir   \n",
       "7                 TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack   \n",
       "8                                                                                          \n",
       "9                                                                                          \n",
       "10                                                                                         \n",
       "11                                                                                         \n",
       "12                                                                                         \n",
       "13                                                                                         \n",
       "14                                                                                         \n",
       "15                                                                                         \n",
       "16                                                                                         \n",
       "17                                                                                         \n",
       "18                                                                                         \n",
       "19                                                                                         \n",
       "20                                                                                         \n",
       "21                                                                                         \n",
       "22                                                                                         \n",
       "23                                                                                         \n",
       "24                                                                                         \n",
       "25                                                                                         \n",
       "26                                                                                         \n",
       "27                                                                                         \n",
       "28                                                                                         \n",
       "29                                                                                         \n",
       "30                                                                                         \n",
       "31                                                                                         \n",
       "32                                                                                         \n",
       "33                                                                                         \n",
       "\n",
       "                                                                                                                                                                                                                                            Valid and Reliable  \n",
       "0   Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World  \n",
       "1                                                                                                                                                             Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity  \n",
       "2                                                                                                                                                                                                                   Big-bench: Context Free Question Answering  \n",
       "3                                                                                                                                                                         Big-bench: Contextual question answering, Reading comprehension, Question generation  \n",
       "4                                                                                                                                                                                                                       Big-bench: Morphology, Grammar, Syntax  \n",
       "5                                                                                                                                                                                                                               Big-bench: Out-of-Distribution  \n",
       "6                                                                                                                                                                                                                                        Big-bench: Paraphrase  \n",
       "7                                                                                                                                                                                                                            Big-bench: Sufficient information  \n",
       "8                                                                                                                                                                                                                                     Big-bench: Summarization  \n",
       "9                                                                                                                          DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking  \n",
       "10                                                                                                                                                                                                                        Eval Gauntlet\\nReading comprehension  \n",
       "11                                                                                                                                                                                 Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming  \n",
       "12                                                                                                                                                                                                                      Eval Gauntlet: Language Understanding   \n",
       "13                                                                                                                                                                                                                              Eval Gauntlet: World Knowledge  \n",
       "14                                                                                                                                                                                                                                   Evaluation Harness: BLiMP  \n",
       "15                                                                                                                                                                                                                               Evaluation Harness: CoQA, ARC  \n",
       "16                                                                                                                                                                                                                                    Evaluation Harness: GLUE  \n",
       "17                                                                                                                                                                                                       Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA  \n",
       "18                                                                                                                                                                                                                                  Evaluation Harness: MuTual  \n",
       "19                                                                                                                                                                                              Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP  \n",
       "20                                                                                                                                                             FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness  \n",
       "21                                                                                                                                                                                                             FLASK: Readability, Conciseness, Insightfulness  \n",
       "22                                                                                                                                                                                                                                             HELM: Knowledge  \n",
       "23                                                                                                                                                                                                                                              HELM: Language  \n",
       "24                                                                                                                                                                                                                                   HELM: Text classification  \n",
       "25                                                                                                                                                                                                                                    HELM: Question answering  \n",
       "26                                                                                                                                                                                                                                             HELM: Reasoning  \n",
       "27                                                                                                                                                                                                                           HELM: Robustness to contrast sets  \n",
       "28                                                                                                                                                                                                                                         HELM: Summarization  \n",
       "29                                                                                                                                                                                                     Hugging Face: Fill-mask, Text generation - Benchmarking  \n",
       "30                                                                                                                                                                                                                            Hugging Face: Question answering  \n",
       "31                                                                                                                                                                                                                                 Hugging Face: Summarization  \n",
       "32                                                                                                                                                                           Hugging Face: Text classification, Token classification, Zero-shot classification  \n",
       "33                                                                                                                                                                                                                                                    MT-bench  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'..' + os.sep + 'data' + os.sep + 'data.pkl', 'rb') as fp:\n",
    "    data_dict = pickle.load(fp)\n",
    "\n",
    "data_dict['low_risk_measure_by_tc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a8864a-22b6-400a-b5c1-400667050274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Accountable and Transparent \\\\\n",
      "\\midrule\n",
      "An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B) \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "DecodingTrust: Machine Ethics \\\\\n",
      "Evaluation Harness: ETHICS \\\\\n",
      "HELM: Copyright \\\\\n",
      "LegalBench  \\\\\n",
      "Mark My Words \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Explainable and Interpretable \\\\\n",
      "\\midrule\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Fair with Harmful Bias Managed \\\\\n",
      "\\midrule\n",
      "BELEBELE \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Toxicity \\\\\n",
      "MASSIVE \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Privacy Enhanced \\\\\n",
      "\\midrule\n",
      "HELM: Copyright \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Safe \\\\\n",
      "\\midrule\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "Mark My Words \\\\\n",
      "MLCommons \\\\\n",
      "The WMDP Benchmark \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Secure and Resilient \\\\\n",
      "\\midrule\n",
      "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation \\\\\n",
      "DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations \\\\\n",
      "detect-pretrain-code \\\\\n",
      "In-The-Wild Jailbreak Prompts on LLMs \\\\\n",
      "JailbreakingLLMs\n",
      " \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      "TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Valid and Reliable \\\\\n",
      "\\midrule\n",
      "Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World \\\\\n",
      "Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity \\\\\n",
      "Big-bench: Context Free Question Answering \\\\\n",
      "Big-bench: Contextual question answering, Reading comprehension, Question generation \\\\\n",
      "Big-bench: Morphology, Grammar, Syntax \\\\\n",
      "Big-bench: Out-of-Distribution \\\\\n",
      "Big-bench: Paraphrase \\\\\n",
      "Big-bench: Sufficient information \\\\\n",
      "Big-bench: Summarization \\\\\n",
      "DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking \\\\\n",
      "Eval Gauntlet\n",
      "Reading comprehension \\\\\n",
      "Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming \\\\\n",
      "Eval Gauntlet: Language Understanding  \\\\\n",
      "Eval Gauntlet: World Knowledge \\\\\n",
      "Evaluation Harness: BLiMP \\\\\n",
      "Evaluation Harness: CoQA, ARC \\\\\n",
      "Evaluation Harness: GLUE \\\\\n",
      "Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA \\\\\n",
      "Evaluation Harness: MuTual \\\\\n",
      "Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP \\\\\n",
      "FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness \\\\\n",
      "FLASK: Readability, Conciseness, Insightfulness \\\\\n",
      "HELM: Knowledge \\\\\n",
      "HELM: Language \\\\\n",
      "HELM: Text classification \\\\\n",
      "HELM: Question answering \\\\\n",
      "HELM: Reasoning \\\\\n",
      "HELM: Robustness to contrast sets \\\\\n",
      "HELM: Summarization \\\\\n",
      "Hugging Face: Fill-mask, Text generation - Benchmarking \\\\\n",
      "Hugging Face: Question answering \\\\\n",
      "Hugging Face: Summarization \\\\\n",
      "Hugging Face: Text classification, Token classification, Zero-shot classification \\\\\n",
      "MT-bench \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tc in data_dict['low_risk_measure_by_tc'].columns:\n",
    "    print(data_dict['low_risk_measure_by_tc'][tc].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e5df13-08e1-4c59-a104-6c2942610e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBRN Information': ['Safe'],\n",
       " 'Confabulation': ['Fair with Harmful Bias Managed',\n",
       "  'Safe',\n",
       "  'Valid and Reliable'],\n",
       " 'Dangerous or Violent Recommendations': ['Safe', 'Secure and Resilient'],\n",
       " 'Data Privacy': ['Accountable and Transparent',\n",
       "  'Privacy Enhanced',\n",
       "  'Safe',\n",
       "  'Secure and Resilient'],\n",
       " 'Environmental': ['Accountable and Transparent',\n",
       "  'Fair with Harmful Bias Managed',\n",
       "  'Safe'],\n",
       " 'Human-AI Configuration': ['Accountable and Transparent',\n",
       "  'Explainable and Interpretable',\n",
       "  'Fair with Harmful Bias Managed',\n",
       "  'Privacy Enhanced',\n",
       "  'Safe',\n",
       "  'Secure and Resilient',\n",
       "  'Valid and Reliable'],\n",
       " 'Information Integrity': ['Accountable and Transparent',\n",
       "  'Safe',\n",
       "  'Valid and Reliable'],\n",
       " 'Information Security': ['Privacy Enhanced',\n",
       "  'Safe',\n",
       "  'Secure and Resilient',\n",
       "  'Valid and Reliable'],\n",
       " 'Intellectual Property': ['Accountable and Transparent',\n",
       "  'Fair with Harmful Bias Managed',\n",
       "  'Privacy Enhanced'],\n",
       " 'Obscene, Degrading, and/or Abusive Content': ['Fair with Harmful Bias Managed',\n",
       "  'Safe'],\n",
       " 'Toxicity, Bias, and Homogenization': ['Fair with Harmful Bias Managed',\n",
       "  'Valid and Reliable'],\n",
       " 'Value Chain and Component Integration': ['Accountable and Transparent',\n",
       "  'Explainable and Interpretable',\n",
       "  'Fair with Harmful Bias Managed',\n",
       "  'Privacy Enhanced',\n",
       "  'Safe',\n",
       "  'Secure and Resilient',\n",
       "  'Valid and Reliable']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'..' + os.sep + 'data' + os.sep + 'gai_risk_to_tc_map.pkl', 'rb') as fp:\n",
    "    gai_risk_to_tc_map = pickle.load(fp)\n",
    "\n",
    "gai_risk_to_tc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d44fae-1c82-4e95-968e-53c5ab727dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBRN Information': None,\n",
       " 'Confabulation': None,\n",
       " 'Dangerous or Violent Recommendations': None,\n",
       " 'Data Privacy': None,\n",
       " 'Environmental': None,\n",
       " 'Human-AI Configuration': None,\n",
       " 'Information Integrity': None,\n",
       " 'Information Security': None,\n",
       " 'Intellectual Property': None,\n",
       " 'Obscene, Degrading, and/or Abusive Content': None,\n",
       " 'Toxicity, Bias, and Homogenization': None,\n",
       " 'Value Chain and Component Integration': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_dict = {key: None for key in list(data_dict['gai_risk']['Risk'])}\n",
    "intermediate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb98589a-965e-4828-beae-8fff7e2b1da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBRN Information 6\n",
      "Confabulation 59\n",
      "Dangerous or Violent Recommendations 14\n",
      "Data Privacy 19\n",
      "Environmental 30\n",
      "Human-AI Configuration 72\n",
      "Information Integrity 45\n",
      "Information Security 49\n",
      "Intellectual Property 28\n",
      "Obscene, Degrading, and/or Abusive Content 25\n",
      "Toxicity, Bias, and Homogenization 53\n",
      "Value Chain and Component Integration 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CBRN Information': ['Big-bench: Convince Me',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'MLCommons',\n",
       "  'Mark My Words',\n",
       "  'The WMDP Benchmark'],\n",
       " 'Confabulation': ['BELEBELE',\n",
       "  'Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World',\n",
       "  'Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity',\n",
       "  'Big-bench: Context Free Question Answering',\n",
       "  'Big-bench: Contextual question answering, Reading comprehension, Question generation',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Low-resource language, Non-English, Translation ',\n",
       "  'Big-bench: Morphology, Grammar, Syntax',\n",
       "  'Big-bench: Out-of-Distribution',\n",
       "  'Big-bench: Paraphrase',\n",
       "  'Big-bench: Social bias, Racial bias, Gender bias, Religious bias',\n",
       "  'Big-bench: Sufficient information',\n",
       "  'Big-bench: Summarization',\n",
       "  'Big-bench: Toxicity',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'C-Eval (Chinese evaluation suite)',\n",
       "  'DecodingTrust: Fairness',\n",
       "  'DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking',\n",
       "  'DecodingTrust: Stereotype Bias',\n",
       "  'DecodingTrust: Toxicity',\n",
       "  'Eval Gauntlet\\nReading comprehension',\n",
       "  'Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming',\n",
       "  'Eval Gauntlet: Language Understanding ',\n",
       "  'Eval Gauntlet: World Knowledge',\n",
       "  'Evaluation Harness: BLiMP',\n",
       "  'Evaluation Harness: CoQA, ARC',\n",
       "  'Evaluation Harness: CrowS-Pairs ',\n",
       "  'Evaluation Harness: GLUE',\n",
       "  'Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA',\n",
       "  'Evaluation Harness: MuTual',\n",
       "  'Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP',\n",
       "  'Evaluation Harness: ToxiGen',\n",
       "  'FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness',\n",
       "  'FLASK: Readability, Conciseness, Insightfulness',\n",
       "  'Finding New Biases in Language Models with a Holistic Descriptor Dataset',\n",
       "  'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models',\n",
       "  'HELM: Bias',\n",
       "  'HELM: Knowledge',\n",
       "  'HELM: Language',\n",
       "  'HELM: Language (Twitter AAE)',\n",
       "  'HELM: Question answering',\n",
       "  'HELM: Reasoning',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'HELM: Robustness to contrast sets',\n",
       "  'HELM: Summarization',\n",
       "  'HELM: Text classification',\n",
       "  'HELM: Toxicity',\n",
       "  'Hugging Face: Fill-mask, Text generation - Benchmarking',\n",
       "  'Hugging Face: Question answering',\n",
       "  'Hugging Face: Summarization',\n",
       "  'Hugging Face: Text classification, Token classification, Zero-shot classification',\n",
       "  'MASSIVE',\n",
       "  'MLCommons',\n",
       "  'MT-bench',\n",
       "  'MT-bench - Benchmarking (with human and model scoring)',\n",
       "  'Mark My Words',\n",
       "  'The Self-Perception and Political Biases of ChatGPT',\n",
       "  'The WMDP Benchmark',\n",
       "  'Towards Measuring the Representation of Subjective Global Opinions in Language Models'],\n",
       " 'Dangerous or Violent Recommendations': ['Big-bench: Convince Me',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation',\n",
       "  'DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'In-The-Wild Jailbreak Prompts on LLMs',\n",
       "  'JailbreakingLLMs\\n',\n",
       "  'MLCommons',\n",
       "  'Mark My Words',\n",
       "  'TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack',\n",
       "  'The WMDP Benchmark',\n",
       "  'detect-pretrain-code',\n",
       "  'llmprivacy',\n",
       "  'mimir'],\n",
       " 'Data Privacy': ['An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation',\n",
       "  'DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations',\n",
       "  'DecodingTrust: Machine Ethics',\n",
       "  'Evaluation Harness: ETHICS',\n",
       "  'HELM: Copyright',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'In-The-Wild Jailbreak Prompts on LLMs',\n",
       "  'JailbreakingLLMs\\n',\n",
       "  'LegalBench ',\n",
       "  'MLCommons',\n",
       "  'Mark My Words',\n",
       "  'TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack',\n",
       "  'The WMDP Benchmark',\n",
       "  'detect-pretrain-code',\n",
       "  'llmprivacy',\n",
       "  'mimir'],\n",
       " 'Environmental': ['An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)',\n",
       "  'BELEBELE',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Low-resource language, Non-English, Translation ',\n",
       "  'Big-bench: Social bias, Racial bias, Gender bias, Religious bias',\n",
       "  'Big-bench: Toxicity',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'C-Eval (Chinese evaluation suite)',\n",
       "  'DecodingTrust: Fairness',\n",
       "  'DecodingTrust: Machine Ethics',\n",
       "  'DecodingTrust: Stereotype Bias',\n",
       "  'DecodingTrust: Toxicity',\n",
       "  'Evaluation Harness: CrowS-Pairs ',\n",
       "  'Evaluation Harness: ETHICS',\n",
       "  'Evaluation Harness: ToxiGen',\n",
       "  'Finding New Biases in Language Models with a Holistic Descriptor Dataset',\n",
       "  'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models',\n",
       "  'HELM: Bias',\n",
       "  'HELM: Copyright',\n",
       "  'HELM: Language (Twitter AAE)',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'HELM: Toxicity',\n",
       "  'LegalBench ',\n",
       "  'MASSIVE',\n",
       "  'MLCommons',\n",
       "  'MT-bench - Benchmarking (with human and model scoring)',\n",
       "  'Mark My Words',\n",
       "  'The Self-Perception and Political Biases of ChatGPT',\n",
       "  'The WMDP Benchmark',\n",
       "  'Towards Measuring the Representation of Subjective Global Opinions in Language Models'],\n",
       " 'Human-AI Configuration': ['An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)',\n",
       "  'BELEBELE',\n",
       "  'Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World',\n",
       "  'Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity',\n",
       "  'Big-bench: Context Free Question Answering',\n",
       "  'Big-bench: Contextual question answering, Reading comprehension, Question generation',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Low-resource language, Non-English, Translation ',\n",
       "  'Big-bench: Morphology, Grammar, Syntax',\n",
       "  'Big-bench: Out-of-Distribution',\n",
       "  'Big-bench: Paraphrase',\n",
       "  'Big-bench: Social bias, Racial bias, Gender bias, Religious bias',\n",
       "  'Big-bench: Sufficient information',\n",
       "  'Big-bench: Summarization',\n",
       "  'Big-bench: Toxicity',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'C-Eval (Chinese evaluation suite)',\n",
       "  'Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation',\n",
       "  'DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations',\n",
       "  'DecodingTrust: Fairness',\n",
       "  'DecodingTrust: Machine Ethics',\n",
       "  'DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking',\n",
       "  'DecodingTrust: Stereotype Bias',\n",
       "  'DecodingTrust: Toxicity',\n",
       "  'Eval Gauntlet\\nReading comprehension',\n",
       "  'Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming',\n",
       "  'Eval Gauntlet: Language Understanding ',\n",
       "  'Eval Gauntlet: World Knowledge',\n",
       "  'Evaluation Harness: BLiMP',\n",
       "  'Evaluation Harness: CoQA, ARC',\n",
       "  'Evaluation Harness: CrowS-Pairs ',\n",
       "  'Evaluation Harness: ETHICS',\n",
       "  'Evaluation Harness: GLUE',\n",
       "  'Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA',\n",
       "  'Evaluation Harness: MuTual',\n",
       "  'Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP',\n",
       "  'Evaluation Harness: ToxiGen',\n",
       "  'FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness',\n",
       "  'FLASK: Readability, Conciseness, Insightfulness',\n",
       "  'Finding New Biases in Language Models with a Holistic Descriptor Dataset',\n",
       "  'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models',\n",
       "  'HELM: Bias',\n",
       "  'HELM: Copyright',\n",
       "  'HELM: Knowledge',\n",
       "  'HELM: Language',\n",
       "  'HELM: Language (Twitter AAE)',\n",
       "  'HELM: Question answering',\n",
       "  'HELM: Reasoning',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'HELM: Robustness to contrast sets',\n",
       "  'HELM: Summarization',\n",
       "  'HELM: Text classification',\n",
       "  'HELM: Toxicity',\n",
       "  'Hugging Face: Fill-mask, Text generation - Benchmarking',\n",
       "  'Hugging Face: Question answering',\n",
       "  'Hugging Face: Summarization',\n",
       "  'Hugging Face: Text classification, Token classification, Zero-shot classification',\n",
       "  'In-The-Wild Jailbreak Prompts on LLMs',\n",
       "  'JailbreakingLLMs\\n',\n",
       "  'LegalBench ',\n",
       "  'MASSIVE',\n",
       "  'MLCommons',\n",
       "  'MT-bench',\n",
       "  'MT-bench - Benchmarking (with human and model scoring)',\n",
       "  'Mark My Words',\n",
       "  'TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack',\n",
       "  'The Self-Perception and Political Biases of ChatGPT',\n",
       "  'The WMDP Benchmark',\n",
       "  'Towards Measuring the Representation of Subjective Global Opinions in Language Models',\n",
       "  'detect-pretrain-code',\n",
       "  'llmprivacy',\n",
       "  'mimir'],\n",
       " 'Information Integrity': ['An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)',\n",
       "  'Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World',\n",
       "  'Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity',\n",
       "  'Big-bench: Context Free Question Answering',\n",
       "  'Big-bench: Contextual question answering, Reading comprehension, Question generation',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Morphology, Grammar, Syntax',\n",
       "  'Big-bench: Out-of-Distribution',\n",
       "  'Big-bench: Paraphrase',\n",
       "  'Big-bench: Sufficient information',\n",
       "  'Big-bench: Summarization',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'DecodingTrust: Machine Ethics',\n",
       "  'DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking',\n",
       "  'Eval Gauntlet\\nReading comprehension',\n",
       "  'Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming',\n",
       "  'Eval Gauntlet: Language Understanding ',\n",
       "  'Eval Gauntlet: World Knowledge',\n",
       "  'Evaluation Harness: BLiMP',\n",
       "  'Evaluation Harness: CoQA, ARC',\n",
       "  'Evaluation Harness: ETHICS',\n",
       "  'Evaluation Harness: GLUE',\n",
       "  'Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA',\n",
       "  'Evaluation Harness: MuTual',\n",
       "  'Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP',\n",
       "  'FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness',\n",
       "  'FLASK: Readability, Conciseness, Insightfulness',\n",
       "  'HELM: Copyright',\n",
       "  'HELM: Knowledge',\n",
       "  'HELM: Language',\n",
       "  'HELM: Question answering',\n",
       "  'HELM: Reasoning',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'HELM: Robustness to contrast sets',\n",
       "  'HELM: Summarization',\n",
       "  'HELM: Text classification',\n",
       "  'Hugging Face: Fill-mask, Text generation - Benchmarking',\n",
       "  'Hugging Face: Question answering',\n",
       "  'Hugging Face: Summarization',\n",
       "  'Hugging Face: Text classification, Token classification, Zero-shot classification',\n",
       "  'LegalBench ',\n",
       "  'MLCommons',\n",
       "  'MT-bench',\n",
       "  'Mark My Words',\n",
       "  'The WMDP Benchmark'],\n",
       " 'Information Security': ['Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World',\n",
       "  'Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity',\n",
       "  'Big-bench: Context Free Question Answering',\n",
       "  'Big-bench: Contextual question answering, Reading comprehension, Question generation',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Morphology, Grammar, Syntax',\n",
       "  'Big-bench: Out-of-Distribution',\n",
       "  'Big-bench: Paraphrase',\n",
       "  'Big-bench: Sufficient information',\n",
       "  'Big-bench: Summarization',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation',\n",
       "  'DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations',\n",
       "  'DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking',\n",
       "  'Eval Gauntlet\\nReading comprehension',\n",
       "  'Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming',\n",
       "  'Eval Gauntlet: Language Understanding ',\n",
       "  'Eval Gauntlet: World Knowledge',\n",
       "  'Evaluation Harness: BLiMP',\n",
       "  'Evaluation Harness: CoQA, ARC',\n",
       "  'Evaluation Harness: GLUE',\n",
       "  'Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA',\n",
       "  'Evaluation Harness: MuTual',\n",
       "  'Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP',\n",
       "  'FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness',\n",
       "  'FLASK: Readability, Conciseness, Insightfulness',\n",
       "  'HELM: Copyright',\n",
       "  'HELM: Knowledge',\n",
       "  'HELM: Language',\n",
       "  'HELM: Question answering',\n",
       "  'HELM: Reasoning',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'HELM: Robustness to contrast sets',\n",
       "  'HELM: Summarization',\n",
       "  'HELM: Text classification',\n",
       "  'Hugging Face: Fill-mask, Text generation - Benchmarking',\n",
       "  'Hugging Face: Question answering',\n",
       "  'Hugging Face: Summarization',\n",
       "  'Hugging Face: Text classification, Token classification, Zero-shot classification',\n",
       "  'In-The-Wild Jailbreak Prompts on LLMs',\n",
       "  'JailbreakingLLMs\\n',\n",
       "  'MLCommons',\n",
       "  'MT-bench',\n",
       "  'Mark My Words',\n",
       "  'TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack',\n",
       "  'The WMDP Benchmark',\n",
       "  'detect-pretrain-code',\n",
       "  'llmprivacy',\n",
       "  'mimir'],\n",
       " 'Intellectual Property': ['An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)',\n",
       "  'BELEBELE',\n",
       "  'Big-bench: Low-resource language, Non-English, Translation ',\n",
       "  'Big-bench: Social bias, Racial bias, Gender bias, Religious bias',\n",
       "  'Big-bench: Toxicity',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'C-Eval (Chinese evaluation suite)',\n",
       "  'DecodingTrust: Fairness',\n",
       "  'DecodingTrust: Machine Ethics',\n",
       "  'DecodingTrust: Stereotype Bias',\n",
       "  'DecodingTrust: Toxicity',\n",
       "  'Evaluation Harness: CrowS-Pairs ',\n",
       "  'Evaluation Harness: ETHICS',\n",
       "  'Evaluation Harness: ToxiGen',\n",
       "  'Finding New Biases in Language Models with a Holistic Descriptor Dataset',\n",
       "  'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models',\n",
       "  'HELM: Bias',\n",
       "  'HELM: Copyright',\n",
       "  'HELM: Language (Twitter AAE)',\n",
       "  'HELM: Toxicity',\n",
       "  'LegalBench ',\n",
       "  'MASSIVE',\n",
       "  'MT-bench - Benchmarking (with human and model scoring)',\n",
       "  'Mark My Words',\n",
       "  'The Self-Perception and Political Biases of ChatGPT',\n",
       "  'Towards Measuring the Representation of Subjective Global Opinions in Language Models',\n",
       "  'llmprivacy',\n",
       "  'mimir'],\n",
       " 'Obscene, Degrading, and/or Abusive Content': ['BELEBELE',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Low-resource language, Non-English, Translation ',\n",
       "  'Big-bench: Social bias, Racial bias, Gender bias, Religious bias',\n",
       "  'Big-bench: Toxicity',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'C-Eval (Chinese evaluation suite)',\n",
       "  'DecodingTrust: Fairness',\n",
       "  'DecodingTrust: Stereotype Bias',\n",
       "  'DecodingTrust: Toxicity',\n",
       "  'Evaluation Harness: CrowS-Pairs ',\n",
       "  'Evaluation Harness: ToxiGen',\n",
       "  'Finding New Biases in Language Models with a Holistic Descriptor Dataset',\n",
       "  'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models',\n",
       "  'HELM: Bias',\n",
       "  'HELM: Language (Twitter AAE)',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'HELM: Toxicity',\n",
       "  'MASSIVE',\n",
       "  'MLCommons',\n",
       "  'MT-bench - Benchmarking (with human and model scoring)',\n",
       "  'Mark My Words',\n",
       "  'The Self-Perception and Political Biases of ChatGPT',\n",
       "  'The WMDP Benchmark',\n",
       "  'Towards Measuring the Representation of Subjective Global Opinions in Language Models'],\n",
       " 'Toxicity, Bias, and Homogenization': ['BELEBELE',\n",
       "  'Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World',\n",
       "  'Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity',\n",
       "  'Big-bench: Context Free Question Answering',\n",
       "  'Big-bench: Contextual question answering, Reading comprehension, Question generation',\n",
       "  'Big-bench: Low-resource language, Non-English, Translation ',\n",
       "  'Big-bench: Morphology, Grammar, Syntax',\n",
       "  'Big-bench: Out-of-Distribution',\n",
       "  'Big-bench: Paraphrase',\n",
       "  'Big-bench: Social bias, Racial bias, Gender bias, Religious bias',\n",
       "  'Big-bench: Sufficient information',\n",
       "  'Big-bench: Summarization',\n",
       "  'Big-bench: Toxicity',\n",
       "  'C-Eval (Chinese evaluation suite)',\n",
       "  'DecodingTrust: Fairness',\n",
       "  'DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking',\n",
       "  'DecodingTrust: Stereotype Bias',\n",
       "  'DecodingTrust: Toxicity',\n",
       "  'Eval Gauntlet\\nReading comprehension',\n",
       "  'Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming',\n",
       "  'Eval Gauntlet: Language Understanding ',\n",
       "  'Eval Gauntlet: World Knowledge',\n",
       "  'Evaluation Harness: BLiMP',\n",
       "  'Evaluation Harness: CoQA, ARC',\n",
       "  'Evaluation Harness: CrowS-Pairs ',\n",
       "  'Evaluation Harness: GLUE',\n",
       "  'Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA',\n",
       "  'Evaluation Harness: MuTual',\n",
       "  'Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP',\n",
       "  'Evaluation Harness: ToxiGen',\n",
       "  'FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness',\n",
       "  'FLASK: Readability, Conciseness, Insightfulness',\n",
       "  'Finding New Biases in Language Models with a Holistic Descriptor Dataset',\n",
       "  'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models',\n",
       "  'HELM: Bias',\n",
       "  'HELM: Knowledge',\n",
       "  'HELM: Language',\n",
       "  'HELM: Language (Twitter AAE)',\n",
       "  'HELM: Question answering',\n",
       "  'HELM: Reasoning',\n",
       "  'HELM: Robustness to contrast sets',\n",
       "  'HELM: Summarization',\n",
       "  'HELM: Text classification',\n",
       "  'HELM: Toxicity',\n",
       "  'Hugging Face: Fill-mask, Text generation - Benchmarking',\n",
       "  'Hugging Face: Question answering',\n",
       "  'Hugging Face: Summarization',\n",
       "  'Hugging Face: Text classification, Token classification, Zero-shot classification',\n",
       "  'MASSIVE',\n",
       "  'MT-bench',\n",
       "  'MT-bench - Benchmarking (with human and model scoring)',\n",
       "  'The Self-Perception and Political Biases of ChatGPT',\n",
       "  'Towards Measuring the Representation of Subjective Global Opinions in Language Models'],\n",
       " 'Value Chain and Component Integration': ['An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)',\n",
       "  'BELEBELE',\n",
       "  'Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World',\n",
       "  'Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity',\n",
       "  'Big-bench: Context Free Question Answering',\n",
       "  'Big-bench: Contextual question answering, Reading comprehension, Question generation',\n",
       "  'Big-bench: Convince Me',\n",
       "  'Big-bench: Low-resource language, Non-English, Translation ',\n",
       "  'Big-bench: Morphology, Grammar, Syntax',\n",
       "  'Big-bench: Out-of-Distribution',\n",
       "  'Big-bench: Paraphrase',\n",
       "  'Big-bench: Social bias, Racial bias, Gender bias, Religious bias',\n",
       "  'Big-bench: Sufficient information',\n",
       "  'Big-bench: Summarization',\n",
       "  'Big-bench: Toxicity',\n",
       "  'Big-bench: Truthfulness',\n",
       "  'C-Eval (Chinese evaluation suite)',\n",
       "  'Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation',\n",
       "  'DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations',\n",
       "  'DecodingTrust: Fairness',\n",
       "  'DecodingTrust: Machine Ethics',\n",
       "  'DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking',\n",
       "  'DecodingTrust: Stereotype Bias',\n",
       "  'DecodingTrust: Toxicity',\n",
       "  'Eval Gauntlet\\nReading comprehension',\n",
       "  'Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming',\n",
       "  'Eval Gauntlet: Language Understanding ',\n",
       "  'Eval Gauntlet: World Knowledge',\n",
       "  'Evaluation Harness: BLiMP',\n",
       "  'Evaluation Harness: CoQA, ARC',\n",
       "  'Evaluation Harness: CrowS-Pairs ',\n",
       "  'Evaluation Harness: ETHICS',\n",
       "  'Evaluation Harness: GLUE',\n",
       "  'Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA',\n",
       "  'Evaluation Harness: MuTual',\n",
       "  'Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP',\n",
       "  'Evaluation Harness: ToxiGen',\n",
       "  'FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness',\n",
       "  'FLASK: Readability, Conciseness, Insightfulness',\n",
       "  'Finding New Biases in Language Models with a Holistic Descriptor Dataset',\n",
       "  'From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models',\n",
       "  'HELM: Bias',\n",
       "  'HELM: Copyright',\n",
       "  'HELM: Knowledge',\n",
       "  'HELM: Language',\n",
       "  'HELM: Language (Twitter AAE)',\n",
       "  'HELM: Question answering',\n",
       "  'HELM: Reasoning',\n",
       "  'HELM: Reiteration, Wedging',\n",
       "  'HELM: Robustness to contrast sets',\n",
       "  'HELM: Summarization',\n",
       "  'HELM: Text classification',\n",
       "  'HELM: Toxicity',\n",
       "  'Hugging Face: Fill-mask, Text generation - Benchmarking',\n",
       "  'Hugging Face: Question answering',\n",
       "  'Hugging Face: Summarization',\n",
       "  'Hugging Face: Text classification, Token classification, Zero-shot classification',\n",
       "  'In-The-Wild Jailbreak Prompts on LLMs',\n",
       "  'JailbreakingLLMs\\n',\n",
       "  'LegalBench ',\n",
       "  'MASSIVE',\n",
       "  'MLCommons',\n",
       "  'MT-bench',\n",
       "  'MT-bench - Benchmarking (with human and model scoring)',\n",
       "  'Mark My Words',\n",
       "  'TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack',\n",
       "  'The Self-Perception and Political Biases of ChatGPT',\n",
       "  'The WMDP Benchmark',\n",
       "  'Towards Measuring the Representation of Subjective Global Opinions in Language Models',\n",
       "  'detect-pretrain-code',\n",
       "  'llmprivacy',\n",
       "  'mimir']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in intermediate_dict:\n",
    "    intermediate_dict[key] = []\n",
    "    for tc in gai_risk_to_tc_map[key]:\n",
    "        intermediate_dict[key] += list(data_dict['low_risk_measure_by_tc'][tc].values)\n",
    "    intermediate_dict[key] = sorted(list(set(intermediate_dict[key])))[1:]\n",
    "    print(key, len(intermediate_dict[key]))\n",
    "    \n",
    "intermediate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60639db-a00b-4e76-906a-e8ed886dd9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Risk</th>\n",
       "      <th>CBRN Information</th>\n",
       "      <th>Confabulation</th>\n",
       "      <th>Dangerous or Violent Recommendations</th>\n",
       "      <th>Data Privacy</th>\n",
       "      <th>Environmental</th>\n",
       "      <th>Human-AI Configuration</th>\n",
       "      <th>Information Integrity</th>\n",
       "      <th>Information Security</th>\n",
       "      <th>Intellectual Property</th>\n",
       "      <th>Obscene, Degrading, and/or Abusive Content</th>\n",
       "      <th>Toxicity, Bias, and Homogenization</th>\n",
       "      <th>Value Chain and Component Integration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>BELEBELE</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)</td>\n",
       "      <td>An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)</td>\n",
       "      <td>An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)</td>\n",
       "      <td>An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)</td>\n",
       "      <td>Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World</td>\n",
       "      <td>An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)</td>\n",
       "      <td>BELEBELE</td>\n",
       "      <td>BELEBELE</td>\n",
       "      <td>An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>BELEBELE</td>\n",
       "      <td>BELEBELE</td>\n",
       "      <td>Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World</td>\n",
       "      <td>Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity</td>\n",
       "      <td>BELEBELE</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World</td>\n",
       "      <td>BELEBELE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td>Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity</td>\n",
       "      <td>Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World</td>\n",
       "      <td>Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity</td>\n",
       "      <td>Big-bench: Context Free Question Answering</td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "      <td>Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity</td>\n",
       "      <td>Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLCommons</td>\n",
       "      <td>Big-bench: Context Free Question Answering</td>\n",
       "      <td>DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations</td>\n",
       "      <td>Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation</td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "      <td>Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity</td>\n",
       "      <td>Big-bench: Context Free Question Answering</td>\n",
       "      <td>Big-bench: Contextual question answering, Reading comprehension, Question generation</td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "      <td>Big-bench: Context Free Question Answering</td>\n",
       "      <td>Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>Big-bench: Contextual question answering, Reading comprehension, Question generation</td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td>DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations</td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "      <td>Big-bench: Context Free Question Answering</td>\n",
       "      <td>Big-bench: Contextual question answering, Reading comprehension, Question generation</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "      <td>Big-bench: Contextual question answering, Reading comprehension, Question generation</td>\n",
       "      <td>Big-bench: Context Free Question Answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>In-The-Wild Jailbreak Prompts on LLMs</td>\n",
       "      <td>DecodingTrust: Machine Ethics</td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "      <td>Big-bench: Contextual question answering, Reading comprehension, Question generation</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>Big-bench: Morphology, Grammar, Syntax</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "      <td>Big-bench: Contextual question answering, Reading comprehension, Question generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "      <td>JailbreakingLLMs\\n</td>\n",
       "      <td>Evaluation Harness: ETHICS</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "      <td>Big-bench: Morphology, Grammar, Syntax</td>\n",
       "      <td>Big-bench: Out-of-Distribution</td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "      <td>Big-bench: Morphology, Grammar, Syntax</td>\n",
       "      <td>Big-bench: Convince Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Morphology, Grammar, Syntax</td>\n",
       "      <td>MLCommons</td>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "      <td>Big-bench: Out-of-Distribution</td>\n",
       "      <td>Big-bench: Paraphrase</td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "      <td>Big-bench: Out-of-Distribution</td>\n",
       "      <td>Big-bench: Low-resource language, Non-English, Translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Out-of-Distribution</td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "      <td>Big-bench: Morphology, Grammar, Syntax</td>\n",
       "      <td>Big-bench: Paraphrase</td>\n",
       "      <td>Big-bench: Sufficient information</td>\n",
       "      <td>DecodingTrust: Machine Ethics</td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "      <td>Big-bench: Paraphrase</td>\n",
       "      <td>Big-bench: Morphology, Grammar, Syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Paraphrase</td>\n",
       "      <td>TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack</td>\n",
       "      <td>In-The-Wild Jailbreak Prompts on LLMs</td>\n",
       "      <td>DecodingTrust: Machine Ethics</td>\n",
       "      <td>Big-bench: Out-of-Distribution</td>\n",
       "      <td>Big-bench: Sufficient information</td>\n",
       "      <td>Big-bench: Summarization</td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "      <td>Big-bench: Out-of-Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td>JailbreakingLLMs\\n</td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "      <td>Big-bench: Paraphrase</td>\n",
       "      <td>Big-bench: Summarization</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "      <td>Big-bench: Sufficient information</td>\n",
       "      <td>Big-bench: Paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Sufficient information</td>\n",
       "      <td>detect-pretrain-code</td>\n",
       "      <td>LegalBench</td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation</td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "      <td>Big-bench: Summarization</td>\n",
       "      <td>Big-bench: Social bias, Racial bias, Gender bias, Religious bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Summarization</td>\n",
       "      <td>llmprivacy</td>\n",
       "      <td>MLCommons</td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "      <td>Big-bench: Sufficient information</td>\n",
       "      <td>DecodingTrust: Machine Ethics</td>\n",
       "      <td>DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations</td>\n",
       "      <td>Evaluation Harness: ETHICS</td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "      <td>Big-bench: Sufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "      <td>mimir</td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>Evaluation Harness: ETHICS</td>\n",
       "      <td>Big-bench: Summarization</td>\n",
       "      <td>DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking</td>\n",
       "      <td>DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking</td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "      <td>Big-bench: Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td></td>\n",
       "      <td>TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack</td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "      <td>Eval Gauntlet\\nReading comprehension</td>\n",
       "      <td>Eval Gauntlet\\nReading comprehension</td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "      <td>HELM: Bias</td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "      <td>Big-bench: Toxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "      <td></td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "      <td>Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming</td>\n",
       "      <td>Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming</td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "      <td>DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking</td>\n",
       "      <td>Big-bench: Truthfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "      <td></td>\n",
       "      <td>detect-pretrain-code</td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "      <td>Eval Gauntlet: Language Understanding</td>\n",
       "      <td>Eval Gauntlet: Language Understanding</td>\n",
       "      <td>HELM: Bias</td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "      <td>C-Eval (Chinese evaluation suite)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking</td>\n",
       "      <td></td>\n",
       "      <td>llmprivacy</td>\n",
       "      <td>HELM: Bias</td>\n",
       "      <td>Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation</td>\n",
       "      <td>Eval Gauntlet: World Knowledge</td>\n",
       "      <td>Eval Gauntlet: World Knowledge</td>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "      <td>Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "      <td></td>\n",
       "      <td>mimir</td>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td>DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations</td>\n",
       "      <td>Evaluation Harness: BLiMP</td>\n",
       "      <td>Evaluation Harness: BLiMP</td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "      <td>MASSIVE</td>\n",
       "      <td>Eval Gauntlet\\nReading comprehension</td>\n",
       "      <td>DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "      <td>Evaluation Harness: CoQA, ARC</td>\n",
       "      <td>Evaluation Harness: CoQA, ARC</td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "      <td>MLCommons</td>\n",
       "      <td>Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming</td>\n",
       "      <td>DecodingTrust: Fairness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet\\nReading comprehension</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td>DecodingTrust: Machine Ethics</td>\n",
       "      <td>Evaluation Harness: ETHICS</td>\n",
       "      <td>Evaluation Harness: GLUE</td>\n",
       "      <td>LegalBench</td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "      <td>Eval Gauntlet: Language Understanding</td>\n",
       "      <td>DecodingTrust: Machine Ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "      <td>DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking</td>\n",
       "      <td>Evaluation Harness: GLUE</td>\n",
       "      <td>Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA</td>\n",
       "      <td>MASSIVE</td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>Eval Gauntlet: World Knowledge</td>\n",
       "      <td>DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet: Language Understanding</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LegalBench</td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "      <td>Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA</td>\n",
       "      <td>Evaluation Harness: MuTual</td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "      <td>Evaluation Harness: BLiMP</td>\n",
       "      <td>DecodingTrust: Stereotype Bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>Eval Gauntlet: World Knowledge</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MASSIVE</td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "      <td>Evaluation Harness: MuTual</td>\n",
       "      <td>Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP</td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td>Evaluation Harness: CoQA, ARC</td>\n",
       "      <td>DecodingTrust: Toxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: BLiMP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MLCommons</td>\n",
       "      <td>Eval Gauntlet\\nReading comprehension</td>\n",
       "      <td>Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP</td>\n",
       "      <td>FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness</td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "      <td>Eval Gauntlet\\nReading comprehension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: CoQA, ARC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "      <td>Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming</td>\n",
       "      <td>FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness</td>\n",
       "      <td>FLASK: Readability, Conciseness, Insightfulness</td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: GLUE</td>\n",
       "      <td>Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>Eval Gauntlet: Language Understanding</td>\n",
       "      <td>FLASK: Readability, Conciseness, Insightfulness</td>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td>llmprivacy</td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA</td>\n",
       "      <td>Eval Gauntlet: Language Understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: GLUE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "      <td>Eval Gauntlet: World Knowledge</td>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td>HELM: Knowledge</td>\n",
       "      <td>mimir</td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: MuTual</td>\n",
       "      <td>Eval Gauntlet: World Knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td>Evaluation Harness: BLiMP</td>\n",
       "      <td>HELM: Knowledge</td>\n",
       "      <td>HELM: Language</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP</td>\n",
       "      <td>Evaluation Harness: BLiMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: MuTual</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "      <td>Evaluation Harness: CoQA, ARC</td>\n",
       "      <td>HELM: Language</td>\n",
       "      <td>HELM: Question answering</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "      <td>Evaluation Harness: CoQA, ARC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "      <td>HELM: Question answering</td>\n",
       "      <td>HELM: Reasoning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness</td>\n",
       "      <td>Evaluation Harness: CrowS-Pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: ETHICS</td>\n",
       "      <td>HELM: Reasoning</td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FLASK: Readability, Conciseness, Insightfulness</td>\n",
       "      <td>Evaluation Harness: ETHICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: GLUE</td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td>HELM: Robustness to contrast sets</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "      <td>Evaluation Harness: GLUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>FLASK: Readability, Conciseness, Insightfulness</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA</td>\n",
       "      <td>HELM: Robustness to contrast sets</td>\n",
       "      <td>HELM: Summarization</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "      <td>Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: MuTual</td>\n",
       "      <td>HELM: Summarization</td>\n",
       "      <td>HELM: Text classification</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Bias</td>\n",
       "      <td>Evaluation Harness: MuTual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td></td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP</td>\n",
       "      <td>HELM: Text classification</td>\n",
       "      <td>Hugging Face: Fill-mask, Text generation - Benchmarking</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Knowledge</td>\n",
       "      <td>Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Bias</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "      <td>Hugging Face: Fill-mask, Text generation - Benchmarking</td>\n",
       "      <td>Hugging Face: Question answering</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Language</td>\n",
       "      <td>Evaluation Harness: ToxiGen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Knowledge</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness</td>\n",
       "      <td>Hugging Face: Question answering</td>\n",
       "      <td>Hugging Face: Summarization</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "      <td>FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Language</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FLASK: Readability, Conciseness, Insightfulness</td>\n",
       "      <td>Hugging Face: Summarization</td>\n",
       "      <td>Hugging Face: Text classification, Token classification, Zero-shot classification</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Question answering</td>\n",
       "      <td>FLASK: Readability, Conciseness, Insightfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "      <td>Hugging Face: Text classification, Token classification, Zero-shot classification</td>\n",
       "      <td>In-The-Wild Jailbreak Prompts on LLMs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Reasoning</td>\n",
       "      <td>Finding New Biases in Language Models with a Holistic Descriptor Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Question answering</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "      <td>LegalBench</td>\n",
       "      <td>JailbreakingLLMs\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Robustness to contrast sets</td>\n",
       "      <td>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Reasoning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Bias</td>\n",
       "      <td>MLCommons</td>\n",
       "      <td>MLCommons</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Summarization</td>\n",
       "      <td>HELM: Bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Copyright</td>\n",
       "      <td>MT-bench</td>\n",
       "      <td>MT-bench</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Text classification</td>\n",
       "      <td>HELM: Copyright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Robustness to contrast sets</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Knowledge</td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "      <td>HELM: Knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Summarization</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Language</td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td>TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Fill-mask, Text generation - Benchmarking</td>\n",
       "      <td>HELM: Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Text classification</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "      <td></td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Question answering</td>\n",
       "      <td>HELM: Language (Twitter AAE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td></td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Question answering</td>\n",
       "      <td></td>\n",
       "      <td>detect-pretrain-code</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Summarization</td>\n",
       "      <td>HELM: Question answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Fill-mask, Text generation - Benchmarking</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Reasoning</td>\n",
       "      <td></td>\n",
       "      <td>llmprivacy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Text classification, Token classification, Zero-shot classification</td>\n",
       "      <td>HELM: Reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Question answering</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "      <td></td>\n",
       "      <td>mimir</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MASSIVE</td>\n",
       "      <td>HELM: Reiteration, Wedging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Summarization</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Robustness to contrast sets</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench</td>\n",
       "      <td>HELM: Robustness to contrast sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Text classification, Token classification, Zero-shot classification</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Summarization</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "      <td>HELM: Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td></td>\n",
       "      <td>MASSIVE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Text classification</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "      <td>HELM: Text classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td></td>\n",
       "      <td>MLCommons</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "      <td>HELM: Toxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td></td>\n",
       "      <td>MT-bench</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Fill-mask, Text generation - Benchmarking</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Fill-mask, Text generation - Benchmarking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td></td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Question answering</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Question answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td></td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Summarization</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td></td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Text classification, Token classification, Zero-shot classification</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hugging Face: Text classification, Token classification, Zero-shot classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td></td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>In-The-Wild Jailbreak Prompts on LLMs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>In-The-Wild Jailbreak Prompts on LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td></td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>JailbreakingLLMs\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>JailbreakingLLMs\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LegalBench</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LegalBench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MASSIVE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MASSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MLCommons</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MLCommons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MT-bench - Benchmarking (with human and model scoring)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mark My Words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mark My Words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The Self-Perception and Political Biases of ChatGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The WMDP Benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Towards Measuring the Representation of Subjective Global Opinions in Language Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>detect-pretrain-code</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>detect-pretrain-code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>llmprivacy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>llmprivacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mimir</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mimir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Risk            CBRN Information  \\\n",
       "0         Big-bench: Convince Me   \n",
       "1        Big-bench: Truthfulness   \n",
       "2     HELM: Reiteration, Wedging   \n",
       "3                      MLCommons   \n",
       "4                  Mark My Words   \n",
       "5             The WMDP Benchmark   \n",
       "6                                  \n",
       "7                                  \n",
       "8                                  \n",
       "9                                  \n",
       "10                                 \n",
       "11                                 \n",
       "12                                 \n",
       "13                                 \n",
       "14                                 \n",
       "15                                 \n",
       "16                                 \n",
       "17                                 \n",
       "18                                 \n",
       "19                                 \n",
       "20                                 \n",
       "21                                 \n",
       "22                                 \n",
       "23                                 \n",
       "24                                 \n",
       "25                                 \n",
       "26                                 \n",
       "27                                 \n",
       "28                                 \n",
       "29                                 \n",
       "30                                 \n",
       "31                                 \n",
       "32                                 \n",
       "33                                 \n",
       "34                                 \n",
       "35                                 \n",
       "36                                 \n",
       "37                                 \n",
       "38                                 \n",
       "39                                 \n",
       "40                                 \n",
       "41                                 \n",
       "42                                 \n",
       "43                                 \n",
       "44                                 \n",
       "45                                 \n",
       "46                                 \n",
       "47                                 \n",
       "48                                 \n",
       "49                                 \n",
       "50                                 \n",
       "51                                 \n",
       "52                                 \n",
       "53                                 \n",
       "54                                 \n",
       "55                                 \n",
       "56                                 \n",
       "57                                 \n",
       "58                                 \n",
       "59                                 \n",
       "60                                 \n",
       "61                                 \n",
       "62                                 \n",
       "63                                 \n",
       "64                                 \n",
       "65                                 \n",
       "66                                 \n",
       "67                                 \n",
       "68                                 \n",
       "69                                 \n",
       "70                                 \n",
       "71                                 \n",
       "72                                 \n",
       "73                                 \n",
       "74                                 \n",
       "75                                 \n",
       "76                                 \n",
       "77                                 \n",
       "78                                 \n",
       "\n",
       "Risk                                                                                                                                                                                                                                               Confabulation  \\\n",
       "0                                                                                                                                                                                                                                                       BELEBELE   \n",
       "1     Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World   \n",
       "2                                                                                                                                                               Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity   \n",
       "3                                                                                                                                                                                                                     Big-bench: Context Free Question Answering   \n",
       "4                                                                                                                                                                           Big-bench: Contextual question answering, Reading comprehension, Question generation   \n",
       "5                                                                                                                                                                                                                                         Big-bench: Convince Me   \n",
       "6                                                                                                                                                                                                    Big-bench: Low-resource language, Non-English, Translation    \n",
       "7                                                                                                                                                                                                                         Big-bench: Morphology, Grammar, Syntax   \n",
       "8                                                                                                                                                                                                                                 Big-bench: Out-of-Distribution   \n",
       "9                                                                                                                                                                                                                                          Big-bench: Paraphrase   \n",
       "10                                                                                                                                                                                              Big-bench: Social bias, Racial bias, Gender bias, Religious bias   \n",
       "11                                                                                                                                                                                                                             Big-bench: Sufficient information   \n",
       "12                                                                                                                                                                                                                                      Big-bench: Summarization   \n",
       "13                                                                                                                                                                                                                                           Big-bench: Toxicity   \n",
       "14                                                                                                                                                                                                                                       Big-bench: Truthfulness   \n",
       "15                                                                                                                                                                                                                             C-Eval (Chinese evaluation suite)   \n",
       "16                                                                                                                                                                                                                                       DecodingTrust: Fairness   \n",
       "17                                                                                                                           DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking   \n",
       "18                                                                                                                                                                                                                                DecodingTrust: Stereotype Bias   \n",
       "19                                                                                                                                                                                                                                       DecodingTrust: Toxicity   \n",
       "20                                                                                                                                                                                                                          Eval Gauntlet\\nReading comprehension   \n",
       "21                                                                                                                                                                                   Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming   \n",
       "22                                                                                                                                                                                                                        Eval Gauntlet: Language Understanding    \n",
       "23                                                                                                                                                                                                                                Eval Gauntlet: World Knowledge   \n",
       "24                                                                                                                                                                                                                                     Evaluation Harness: BLiMP   \n",
       "25                                                                                                                                                                                                                                 Evaluation Harness: CoQA, ARC   \n",
       "26                                                                                                                                                                                                                              Evaluation Harness: CrowS-Pairs    \n",
       "27                                                                                                                                                                                                                                      Evaluation Harness: GLUE   \n",
       "28                                                                                                                                                                                                         Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA   \n",
       "29                                                                                                                                                                                                                                    Evaluation Harness: MuTual   \n",
       "30                                                                                                                                                                                                Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP   \n",
       "31                                                                                                                                                                                                                                   Evaluation Harness: ToxiGen   \n",
       "32                                                                                                                                                               FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness   \n",
       "33                                                                                                                                                                                                               FLASK: Readability, Conciseness, Insightfulness   \n",
       "34                                                                                                                                                                                      Finding New Biases in Language Models with a Holistic Descriptor Dataset   \n",
       "35                                                                                                                            From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models   \n",
       "36                                                                                                                                                                                                                                                    HELM: Bias   \n",
       "37                                                                                                                                                                                                                                               HELM: Knowledge   \n",
       "38                                                                                                                                                                                                                                                HELM: Language   \n",
       "39                                                                                                                                                                                                                                  HELM: Language (Twitter AAE)   \n",
       "40                                                                                                                                                                                                                                      HELM: Question answering   \n",
       "41                                                                                                                                                                                                                                               HELM: Reasoning   \n",
       "42                                                                                                                                                                                                                                    HELM: Reiteration, Wedging   \n",
       "43                                                                                                                                                                                                                             HELM: Robustness to contrast sets   \n",
       "44                                                                                                                                                                                                                                           HELM: Summarization   \n",
       "45                                                                                                                                                                                                                                     HELM: Text classification   \n",
       "46                                                                                                                                                                                                                                                HELM: Toxicity   \n",
       "47                                                                                                                                                                                                       Hugging Face: Fill-mask, Text generation - Benchmarking   \n",
       "48                                                                                                                                                                                                                              Hugging Face: Question answering   \n",
       "49                                                                                                                                                                                                                                   Hugging Face: Summarization   \n",
       "50                                                                                                                                                                             Hugging Face: Text classification, Token classification, Zero-shot classification   \n",
       "51                                                                                                                                                                                                                                                       MASSIVE   \n",
       "52                                                                                                                                                                                                                                                     MLCommons   \n",
       "53                                                                                                                                                                                                                                                      MT-bench   \n",
       "54                                                                                                                                                                                                        MT-bench - Benchmarking (with human and model scoring)   \n",
       "55                                                                                                                                                                                                                                                 Mark My Words   \n",
       "56                                                                                                                                                                                                           The Self-Perception and Political Biases of ChatGPT   \n",
       "57                                                                                                                                                                                                                                            The WMDP Benchmark   \n",
       "58                                                                                                                                                                         Towards Measuring the Representation of Subjective Global Opinions in Language Models   \n",
       "59                                                                                                                                                                                                                                                                 \n",
       "60                                                                                                                                                                                                                                                                 \n",
       "61                                                                                                                                                                                                                                                                 \n",
       "62                                                                                                                                                                                                                                                                 \n",
       "63                                                                                                                                                                                                                                                                 \n",
       "64                                                                                                                                                                                                                                                                 \n",
       "65                                                                                                                                                                                                                                                                 \n",
       "66                                                                                                                                                                                                                                                                 \n",
       "67                                                                                                                                                                                                                                                                 \n",
       "68                                                                                                                                                                                                                                                                 \n",
       "69                                                                                                                                                                                                                                                                 \n",
       "70                                                                                                                                                                                                                                                                 \n",
       "71                                                                                                                                                                                                                                                                 \n",
       "72                                                                                                                                                                                                                                                                 \n",
       "73                                                                                                                                                                                                                                                                 \n",
       "74                                                                                                                                                                                                                                                                 \n",
       "75                                                                                                                                                                                                                                                                 \n",
       "76                                                                                                                                                                                                                                                                 \n",
       "77                                                                                                                                                                                                                                                                 \n",
       "78                                                                                                                                                                                                                                                                 \n",
       "\n",
       "Risk                                                  Dangerous or Violent Recommendations  \\\n",
       "0                                                                   Big-bench: Convince Me   \n",
       "1                                                                  Big-bench: Truthfulness   \n",
       "2                     Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation   \n",
       "3     DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations   \n",
       "4                                                               HELM: Reiteration, Wedging   \n",
       "5                                                    In-The-Wild Jailbreak Prompts on LLMs   \n",
       "6                                                                       JailbreakingLLMs\\n   \n",
       "7                                                                                MLCommons   \n",
       "8                                                                            Mark My Words   \n",
       "9                   TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack   \n",
       "10                                                                      The WMDP Benchmark   \n",
       "11                                                                    detect-pretrain-code   \n",
       "12                                                                              llmprivacy   \n",
       "13                                                                                   mimir   \n",
       "14                                                                                           \n",
       "15                                                                                           \n",
       "16                                                                                           \n",
       "17                                                                                           \n",
       "18                                                                                           \n",
       "19                                                                                           \n",
       "20                                                                                           \n",
       "21                                                                                           \n",
       "22                                                                                           \n",
       "23                                                                                           \n",
       "24                                                                                           \n",
       "25                                                                                           \n",
       "26                                                                                           \n",
       "27                                                                                           \n",
       "28                                                                                           \n",
       "29                                                                                           \n",
       "30                                                                                           \n",
       "31                                                                                           \n",
       "32                                                                                           \n",
       "33                                                                                           \n",
       "34                                                                                           \n",
       "35                                                                                           \n",
       "36                                                                                           \n",
       "37                                                                                           \n",
       "38                                                                                           \n",
       "39                                                                                           \n",
       "40                                                                                           \n",
       "41                                                                                           \n",
       "42                                                                                           \n",
       "43                                                                                           \n",
       "44                                                                                           \n",
       "45                                                                                           \n",
       "46                                                                                           \n",
       "47                                                                                           \n",
       "48                                                                                           \n",
       "49                                                                                           \n",
       "50                                                                                           \n",
       "51                                                                                           \n",
       "52                                                                                           \n",
       "53                                                                                           \n",
       "54                                                                                           \n",
       "55                                                                                           \n",
       "56                                                                                           \n",
       "57                                                                                           \n",
       "58                                                                                           \n",
       "59                                                                                           \n",
       "60                                                                                           \n",
       "61                                                                                           \n",
       "62                                                                                           \n",
       "63                                                                                           \n",
       "64                                                                                           \n",
       "65                                                                                           \n",
       "66                                                                                           \n",
       "67                                                                                           \n",
       "68                                                                                           \n",
       "69                                                                                           \n",
       "70                                                                                           \n",
       "71                                                                                           \n",
       "72                                                                                           \n",
       "73                                                                                           \n",
       "74                                                                                           \n",
       "75                                                                                           \n",
       "76                                                                                           \n",
       "77                                                                                           \n",
       "78                                                                                           \n",
       "\n",
       "Risk                                                                                                    Data Privacy  \\\n",
       "0     An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)   \n",
       "1                                                                                             Big-bench: Convince Me   \n",
       "2                                                                                            Big-bench: Truthfulness   \n",
       "3                                               Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation   \n",
       "4                               DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations   \n",
       "5                                                                                      DecodingTrust: Machine Ethics   \n",
       "6                                                                                         Evaluation Harness: ETHICS   \n",
       "7                                                                                                    HELM: Copyright   \n",
       "8                                                                                         HELM: Reiteration, Wedging   \n",
       "9                                                                              In-The-Wild Jailbreak Prompts on LLMs   \n",
       "10                                                                                                JailbreakingLLMs\\n   \n",
       "11                                                                                                       LegalBench    \n",
       "12                                                                                                         MLCommons   \n",
       "13                                                                                                     Mark My Words   \n",
       "14                                            TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack   \n",
       "15                                                                                                The WMDP Benchmark   \n",
       "16                                                                                              detect-pretrain-code   \n",
       "17                                                                                                        llmprivacy   \n",
       "18                                                                                                             mimir   \n",
       "19                                                                                                                     \n",
       "20                                                                                                                     \n",
       "21                                                                                                                     \n",
       "22                                                                                                                     \n",
       "23                                                                                                                     \n",
       "24                                                                                                                     \n",
       "25                                                                                                                     \n",
       "26                                                                                                                     \n",
       "27                                                                                                                     \n",
       "28                                                                                                                     \n",
       "29                                                                                                                     \n",
       "30                                                                                                                     \n",
       "31                                                                                                                     \n",
       "32                                                                                                                     \n",
       "33                                                                                                                     \n",
       "34                                                                                                                     \n",
       "35                                                                                                                     \n",
       "36                                                                                                                     \n",
       "37                                                                                                                     \n",
       "38                                                                                                                     \n",
       "39                                                                                                                     \n",
       "40                                                                                                                     \n",
       "41                                                                                                                     \n",
       "42                                                                                                                     \n",
       "43                                                                                                                     \n",
       "44                                                                                                                     \n",
       "45                                                                                                                     \n",
       "46                                                                                                                     \n",
       "47                                                                                                                     \n",
       "48                                                                                                                     \n",
       "49                                                                                                                     \n",
       "50                                                                                                                     \n",
       "51                                                                                                                     \n",
       "52                                                                                                                     \n",
       "53                                                                                                                     \n",
       "54                                                                                                                     \n",
       "55                                                                                                                     \n",
       "56                                                                                                                     \n",
       "57                                                                                                                     \n",
       "58                                                                                                                     \n",
       "59                                                                                                                     \n",
       "60                                                                                                                     \n",
       "61                                                                                                                     \n",
       "62                                                                                                                     \n",
       "63                                                                                                                     \n",
       "64                                                                                                                     \n",
       "65                                                                                                                     \n",
       "66                                                                                                                     \n",
       "67                                                                                                                     \n",
       "68                                                                                                                     \n",
       "69                                                                                                                     \n",
       "70                                                                                                                     \n",
       "71                                                                                                                     \n",
       "72                                                                                                                     \n",
       "73                                                                                                                     \n",
       "74                                                                                                                     \n",
       "75                                                                                                                     \n",
       "76                                                                                                                     \n",
       "77                                                                                                                     \n",
       "78                                                                                                                     \n",
       "\n",
       "Risk                                                                                                                       Environmental  \\\n",
       "0                         An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)   \n",
       "1                                                                                                                               BELEBELE   \n",
       "2                                                                                                                 Big-bench: Convince Me   \n",
       "3                                                                            Big-bench: Low-resource language, Non-English, Translation    \n",
       "4                                                                       Big-bench: Social bias, Racial bias, Gender bias, Religious bias   \n",
       "5                                                                                                                    Big-bench: Toxicity   \n",
       "6                                                                                                                Big-bench: Truthfulness   \n",
       "7                                                                                                      C-Eval (Chinese evaluation suite)   \n",
       "8                                                                                                                DecodingTrust: Fairness   \n",
       "9                                                                                                          DecodingTrust: Machine Ethics   \n",
       "10                                                                                                        DecodingTrust: Stereotype Bias   \n",
       "11                                                                                                               DecodingTrust: Toxicity   \n",
       "12                                                                                                      Evaluation Harness: CrowS-Pairs    \n",
       "13                                                                                                            Evaluation Harness: ETHICS   \n",
       "14                                                                                                           Evaluation Harness: ToxiGen   \n",
       "15                                                              Finding New Biases in Language Models with a Holistic Descriptor Dataset   \n",
       "16    From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models   \n",
       "17                                                                                                                            HELM: Bias   \n",
       "18                                                                                                                       HELM: Copyright   \n",
       "19                                                                                                          HELM: Language (Twitter AAE)   \n",
       "20                                                                                                            HELM: Reiteration, Wedging   \n",
       "21                                                                                                                        HELM: Toxicity   \n",
       "22                                                                                                                           LegalBench    \n",
       "23                                                                                                                               MASSIVE   \n",
       "24                                                                                                                             MLCommons   \n",
       "25                                                                                MT-bench - Benchmarking (with human and model scoring)   \n",
       "26                                                                                                                         Mark My Words   \n",
       "27                                                                                   The Self-Perception and Political Biases of ChatGPT   \n",
       "28                                                                                                                    The WMDP Benchmark   \n",
       "29                                                 Towards Measuring the Representation of Subjective Global Opinions in Language Models   \n",
       "30                                                                                                                                         \n",
       "31                                                                                                                                         \n",
       "32                                                                                                                                         \n",
       "33                                                                                                                                         \n",
       "34                                                                                                                                         \n",
       "35                                                                                                                                         \n",
       "36                                                                                                                                         \n",
       "37                                                                                                                                         \n",
       "38                                                                                                                                         \n",
       "39                                                                                                                                         \n",
       "40                                                                                                                                         \n",
       "41                                                                                                                                         \n",
       "42                                                                                                                                         \n",
       "43                                                                                                                                         \n",
       "44                                                                                                                                         \n",
       "45                                                                                                                                         \n",
       "46                                                                                                                                         \n",
       "47                                                                                                                                         \n",
       "48                                                                                                                                         \n",
       "49                                                                                                                                         \n",
       "50                                                                                                                                         \n",
       "51                                                                                                                                         \n",
       "52                                                                                                                                         \n",
       "53                                                                                                                                         \n",
       "54                                                                                                                                         \n",
       "55                                                                                                                                         \n",
       "56                                                                                                                                         \n",
       "57                                                                                                                                         \n",
       "58                                                                                                                                         \n",
       "59                                                                                                                                         \n",
       "60                                                                                                                                         \n",
       "61                                                                                                                                         \n",
       "62                                                                                                                                         \n",
       "63                                                                                                                                         \n",
       "64                                                                                                                                         \n",
       "65                                                                                                                                         \n",
       "66                                                                                                                                         \n",
       "67                                                                                                                                         \n",
       "68                                                                                                                                         \n",
       "69                                                                                                                                         \n",
       "70                                                                                                                                         \n",
       "71                                                                                                                                         \n",
       "72                                                                                                                                         \n",
       "73                                                                                                                                         \n",
       "74                                                                                                                                         \n",
       "75                                                                                                                                         \n",
       "76                                                                                                                                         \n",
       "77                                                                                                                                         \n",
       "78                                                                                                                                         \n",
       "\n",
       "Risk                                                                                                                                                                                                                                      Human-AI Configuration  \\\n",
       "0                                                                                                                                                 An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)   \n",
       "1                                                                                                                                                                                                                                                       BELEBELE   \n",
       "2     Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World   \n",
       "3                                                                                                                                                               Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity   \n",
       "4                                                                                                                                                                                                                     Big-bench: Context Free Question Answering   \n",
       "5                                                                                                                                                                           Big-bench: Contextual question answering, Reading comprehension, Question generation   \n",
       "6                                                                                                                                                                                                                                         Big-bench: Convince Me   \n",
       "7                                                                                                                                                                                                    Big-bench: Low-resource language, Non-English, Translation    \n",
       "8                                                                                                                                                                                                                         Big-bench: Morphology, Grammar, Syntax   \n",
       "9                                                                                                                                                                                                                                 Big-bench: Out-of-Distribution   \n",
       "10                                                                                                                                                                                                                                         Big-bench: Paraphrase   \n",
       "11                                                                                                                                                                                              Big-bench: Social bias, Racial bias, Gender bias, Religious bias   \n",
       "12                                                                                                                                                                                                                             Big-bench: Sufficient information   \n",
       "13                                                                                                                                                                                                                                      Big-bench: Summarization   \n",
       "14                                                                                                                                                                                                                                           Big-bench: Toxicity   \n",
       "15                                                                                                                                                                                                                                       Big-bench: Truthfulness   \n",
       "16                                                                                                                                                                                                                             C-Eval (Chinese evaluation suite)   \n",
       "17                                                                                                                                                                                          Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation   \n",
       "18                                                                                                                                                                          DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations   \n",
       "19                                                                                                                                                                                                                                       DecodingTrust: Fairness   \n",
       "20                                                                                                                                                                                                                                 DecodingTrust: Machine Ethics   \n",
       "21                                                                                                                           DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking   \n",
       "22                                                                                                                                                                                                                                DecodingTrust: Stereotype Bias   \n",
       "23                                                                                                                                                                                                                                       DecodingTrust: Toxicity   \n",
       "24                                                                                                                                                                                                                          Eval Gauntlet\\nReading comprehension   \n",
       "25                                                                                                                                                                                   Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming   \n",
       "26                                                                                                                                                                                                                        Eval Gauntlet: Language Understanding    \n",
       "27                                                                                                                                                                                                                                Eval Gauntlet: World Knowledge   \n",
       "28                                                                                                                                                                                                                                     Evaluation Harness: BLiMP   \n",
       "29                                                                                                                                                                                                                                 Evaluation Harness: CoQA, ARC   \n",
       "30                                                                                                                                                                                                                              Evaluation Harness: CrowS-Pairs    \n",
       "31                                                                                                                                                                                                                                    Evaluation Harness: ETHICS   \n",
       "32                                                                                                                                                                                                                                      Evaluation Harness: GLUE   \n",
       "33                                                                                                                                                                                                         Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA   \n",
       "34                                                                                                                                                                                                                                    Evaluation Harness: MuTual   \n",
       "35                                                                                                                                                                                                Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP   \n",
       "36                                                                                                                                                                                                                                   Evaluation Harness: ToxiGen   \n",
       "37                                                                                                                                                               FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness   \n",
       "38                                                                                                                                                                                                               FLASK: Readability, Conciseness, Insightfulness   \n",
       "39                                                                                                                                                                                      Finding New Biases in Language Models with a Holistic Descriptor Dataset   \n",
       "40                                                                                                                            From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models   \n",
       "41                                                                                                                                                                                                                                                    HELM: Bias   \n",
       "42                                                                                                                                                                                                                                               HELM: Copyright   \n",
       "43                                                                                                                                                                                                                                               HELM: Knowledge   \n",
       "44                                                                                                                                                                                                                                                HELM: Language   \n",
       "45                                                                                                                                                                                                                                  HELM: Language (Twitter AAE)   \n",
       "46                                                                                                                                                                                                                                      HELM: Question answering   \n",
       "47                                                                                                                                                                                                                                               HELM: Reasoning   \n",
       "48                                                                                                                                                                                                                                    HELM: Reiteration, Wedging   \n",
       "49                                                                                                                                                                                                                             HELM: Robustness to contrast sets   \n",
       "50                                                                                                                                                                                                                                           HELM: Summarization   \n",
       "51                                                                                                                                                                                                                                     HELM: Text classification   \n",
       "52                                                                                                                                                                                                                                                HELM: Toxicity   \n",
       "53                                                                                                                                                                                                       Hugging Face: Fill-mask, Text generation - Benchmarking   \n",
       "54                                                                                                                                                                                                                              Hugging Face: Question answering   \n",
       "55                                                                                                                                                                                                                                   Hugging Face: Summarization   \n",
       "56                                                                                                                                                                             Hugging Face: Text classification, Token classification, Zero-shot classification   \n",
       "57                                                                                                                                                                                                                         In-The-Wild Jailbreak Prompts on LLMs   \n",
       "58                                                                                                                                                                                                                                            JailbreakingLLMs\\n   \n",
       "59                                                                                                                                                                                                                                                   LegalBench    \n",
       "60                                                                                                                                                                                                                                                       MASSIVE   \n",
       "61                                                                                                                                                                                                                                                     MLCommons   \n",
       "62                                                                                                                                                                                                                                                      MT-bench   \n",
       "63                                                                                                                                                                                                        MT-bench - Benchmarking (with human and model scoring)   \n",
       "64                                                                                                                                                                                                                                                 Mark My Words   \n",
       "65                                                                                                                                                                                        TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack   \n",
       "66                                                                                                                                                                                                           The Self-Perception and Political Biases of ChatGPT   \n",
       "67                                                                                                                                                                                                                                            The WMDP Benchmark   \n",
       "68                                                                                                                                                                         Towards Measuring the Representation of Subjective Global Opinions in Language Models   \n",
       "69                                                                                                                                                                                                                                          detect-pretrain-code   \n",
       "70                                                                                                                                                                                                                                                    llmprivacy   \n",
       "71                                                                                                                                                                                                                                                         mimir   \n",
       "72                                                                                                                                                                                                                                                                 \n",
       "73                                                                                                                                                                                                                                                                 \n",
       "74                                                                                                                                                                                                                                                                 \n",
       "75                                                                                                                                                                                                                                                                 \n",
       "76                                                                                                                                                                                                                                                                 \n",
       "77                                                                                                                                                                                                                                                                 \n",
       "78                                                                                                                                                                                                                                                                 \n",
       "\n",
       "Risk                                                                                                                                                                                                                                       Information Integrity  \\\n",
       "0                                                                                                                                                 An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)   \n",
       "1     Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World   \n",
       "2                                                                                                                                                               Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity   \n",
       "3                                                                                                                                                                                                                     Big-bench: Context Free Question Answering   \n",
       "4                                                                                                                                                                           Big-bench: Contextual question answering, Reading comprehension, Question generation   \n",
       "5                                                                                                                                                                                                                                         Big-bench: Convince Me   \n",
       "6                                                                                                                                                                                                                         Big-bench: Morphology, Grammar, Syntax   \n",
       "7                                                                                                                                                                                                                                 Big-bench: Out-of-Distribution   \n",
       "8                                                                                                                                                                                                                                          Big-bench: Paraphrase   \n",
       "9                                                                                                                                                                                                                              Big-bench: Sufficient information   \n",
       "10                                                                                                                                                                                                                                      Big-bench: Summarization   \n",
       "11                                                                                                                                                                                                                                       Big-bench: Truthfulness   \n",
       "12                                                                                                                                                                                                                                 DecodingTrust: Machine Ethics   \n",
       "13                                                                                                                           DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking   \n",
       "14                                                                                                                                                                                                                          Eval Gauntlet\\nReading comprehension   \n",
       "15                                                                                                                                                                                   Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming   \n",
       "16                                                                                                                                                                                                                        Eval Gauntlet: Language Understanding    \n",
       "17                                                                                                                                                                                                                                Eval Gauntlet: World Knowledge   \n",
       "18                                                                                                                                                                                                                                     Evaluation Harness: BLiMP   \n",
       "19                                                                                                                                                                                                                                 Evaluation Harness: CoQA, ARC   \n",
       "20                                                                                                                                                                                                                                    Evaluation Harness: ETHICS   \n",
       "21                                                                                                                                                                                                                                      Evaluation Harness: GLUE   \n",
       "22                                                                                                                                                                                                         Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA   \n",
       "23                                                                                                                                                                                                                                    Evaluation Harness: MuTual   \n",
       "24                                                                                                                                                                                                Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP   \n",
       "25                                                                                                                                                               FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness   \n",
       "26                                                                                                                                                                                                               FLASK: Readability, Conciseness, Insightfulness   \n",
       "27                                                                                                                                                                                                                                               HELM: Copyright   \n",
       "28                                                                                                                                                                                                                                               HELM: Knowledge   \n",
       "29                                                                                                                                                                                                                                                HELM: Language   \n",
       "30                                                                                                                                                                                                                                      HELM: Question answering   \n",
       "31                                                                                                                                                                                                                                               HELM: Reasoning   \n",
       "32                                                                                                                                                                                                                                    HELM: Reiteration, Wedging   \n",
       "33                                                                                                                                                                                                                             HELM: Robustness to contrast sets   \n",
       "34                                                                                                                                                                                                                                           HELM: Summarization   \n",
       "35                                                                                                                                                                                                                                     HELM: Text classification   \n",
       "36                                                                                                                                                                                                       Hugging Face: Fill-mask, Text generation - Benchmarking   \n",
       "37                                                                                                                                                                                                                              Hugging Face: Question answering   \n",
       "38                                                                                                                                                                                                                                   Hugging Face: Summarization   \n",
       "39                                                                                                                                                                             Hugging Face: Text classification, Token classification, Zero-shot classification   \n",
       "40                                                                                                                                                                                                                                                   LegalBench    \n",
       "41                                                                                                                                                                                                                                                     MLCommons   \n",
       "42                                                                                                                                                                                                                                                      MT-bench   \n",
       "43                                                                                                                                                                                                                                                 Mark My Words   \n",
       "44                                                                                                                                                                                                                                            The WMDP Benchmark   \n",
       "45                                                                                                                                                                                                                                                                 \n",
       "46                                                                                                                                                                                                                                                                 \n",
       "47                                                                                                                                                                                                                                                                 \n",
       "48                                                                                                                                                                                                                                                                 \n",
       "49                                                                                                                                                                                                                                                                 \n",
       "50                                                                                                                                                                                                                                                                 \n",
       "51                                                                                                                                                                                                                                                                 \n",
       "52                                                                                                                                                                                                                                                                 \n",
       "53                                                                                                                                                                                                                                                                 \n",
       "54                                                                                                                                                                                                                                                                 \n",
       "55                                                                                                                                                                                                                                                                 \n",
       "56                                                                                                                                                                                                                                                                 \n",
       "57                                                                                                                                                                                                                                                                 \n",
       "58                                                                                                                                                                                                                                                                 \n",
       "59                                                                                                                                                                                                                                                                 \n",
       "60                                                                                                                                                                                                                                                                 \n",
       "61                                                                                                                                                                                                                                                                 \n",
       "62                                                                                                                                                                                                                                                                 \n",
       "63                                                                                                                                                                                                                                                                 \n",
       "64                                                                                                                                                                                                                                                                 \n",
       "65                                                                                                                                                                                                                                                                 \n",
       "66                                                                                                                                                                                                                                                                 \n",
       "67                                                                                                                                                                                                                                                                 \n",
       "68                                                                                                                                                                                                                                                                 \n",
       "69                                                                                                                                                                                                                                                                 \n",
       "70                                                                                                                                                                                                                                                                 \n",
       "71                                                                                                                                                                                                                                                                 \n",
       "72                                                                                                                                                                                                                                                                 \n",
       "73                                                                                                                                                                                                                                                                 \n",
       "74                                                                                                                                                                                                                                                                 \n",
       "75                                                                                                                                                                                                                                                                 \n",
       "76                                                                                                                                                                                                                                                                 \n",
       "77                                                                                                                                                                                                                                                                 \n",
       "78                                                                                                                                                                                                                                                                 \n",
       "\n",
       "Risk                                                                                                                                                                                                                                        Information Security  \\\n",
       "0     Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World   \n",
       "1                                                                                                                                                               Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity   \n",
       "2                                                                                                                                                                                                                     Big-bench: Context Free Question Answering   \n",
       "3                                                                                                                                                                           Big-bench: Contextual question answering, Reading comprehension, Question generation   \n",
       "4                                                                                                                                                                                                                                         Big-bench: Convince Me   \n",
       "5                                                                                                                                                                                                                         Big-bench: Morphology, Grammar, Syntax   \n",
       "6                                                                                                                                                                                                                                 Big-bench: Out-of-Distribution   \n",
       "7                                                                                                                                                                                                                                          Big-bench: Paraphrase   \n",
       "8                                                                                                                                                                                                                              Big-bench: Sufficient information   \n",
       "9                                                                                                                                                                                                                                       Big-bench: Summarization   \n",
       "10                                                                                                                                                                                                                                       Big-bench: Truthfulness   \n",
       "11                                                                                                                                                                                          Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation   \n",
       "12                                                                                                                                                                          DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations   \n",
       "13                                                                                                                           DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking   \n",
       "14                                                                                                                                                                                                                          Eval Gauntlet\\nReading comprehension   \n",
       "15                                                                                                                                                                                   Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming   \n",
       "16                                                                                                                                                                                                                        Eval Gauntlet: Language Understanding    \n",
       "17                                                                                                                                                                                                                                Eval Gauntlet: World Knowledge   \n",
       "18                                                                                                                                                                                                                                     Evaluation Harness: BLiMP   \n",
       "19                                                                                                                                                                                                                                 Evaluation Harness: CoQA, ARC   \n",
       "20                                                                                                                                                                                                                                      Evaluation Harness: GLUE   \n",
       "21                                                                                                                                                                                                         Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA   \n",
       "22                                                                                                                                                                                                                                    Evaluation Harness: MuTual   \n",
       "23                                                                                                                                                                                                Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP   \n",
       "24                                                                                                                                                               FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness   \n",
       "25                                                                                                                                                                                                               FLASK: Readability, Conciseness, Insightfulness   \n",
       "26                                                                                                                                                                                                                                               HELM: Copyright   \n",
       "27                                                                                                                                                                                                                                               HELM: Knowledge   \n",
       "28                                                                                                                                                                                                                                                HELM: Language   \n",
       "29                                                                                                                                                                                                                                      HELM: Question answering   \n",
       "30                                                                                                                                                                                                                                               HELM: Reasoning   \n",
       "31                                                                                                                                                                                                                                    HELM: Reiteration, Wedging   \n",
       "32                                                                                                                                                                                                                             HELM: Robustness to contrast sets   \n",
       "33                                                                                                                                                                                                                                           HELM: Summarization   \n",
       "34                                                                                                                                                                                                                                     HELM: Text classification   \n",
       "35                                                                                                                                                                                                       Hugging Face: Fill-mask, Text generation - Benchmarking   \n",
       "36                                                                                                                                                                                                                              Hugging Face: Question answering   \n",
       "37                                                                                                                                                                                                                                   Hugging Face: Summarization   \n",
       "38                                                                                                                                                                             Hugging Face: Text classification, Token classification, Zero-shot classification   \n",
       "39                                                                                                                                                                                                                         In-The-Wild Jailbreak Prompts on LLMs   \n",
       "40                                                                                                                                                                                                                                            JailbreakingLLMs\\n   \n",
       "41                                                                                                                                                                                                                                                     MLCommons   \n",
       "42                                                                                                                                                                                                                                                      MT-bench   \n",
       "43                                                                                                                                                                                                                                                 Mark My Words   \n",
       "44                                                                                                                                                                                        TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack   \n",
       "45                                                                                                                                                                                                                                            The WMDP Benchmark   \n",
       "46                                                                                                                                                                                                                                          detect-pretrain-code   \n",
       "47                                                                                                                                                                                                                                                    llmprivacy   \n",
       "48                                                                                                                                                                                                                                                         mimir   \n",
       "49                                                                                                                                                                                                                                                                 \n",
       "50                                                                                                                                                                                                                                                                 \n",
       "51                                                                                                                                                                                                                                                                 \n",
       "52                                                                                                                                                                                                                                                                 \n",
       "53                                                                                                                                                                                                                                                                 \n",
       "54                                                                                                                                                                                                                                                                 \n",
       "55                                                                                                                                                                                                                                                                 \n",
       "56                                                                                                                                                                                                                                                                 \n",
       "57                                                                                                                                                                                                                                                                 \n",
       "58                                                                                                                                                                                                                                                                 \n",
       "59                                                                                                                                                                                                                                                                 \n",
       "60                                                                                                                                                                                                                                                                 \n",
       "61                                                                                                                                                                                                                                                                 \n",
       "62                                                                                                                                                                                                                                                                 \n",
       "63                                                                                                                                                                                                                                                                 \n",
       "64                                                                                                                                                                                                                                                                 \n",
       "65                                                                                                                                                                                                                                                                 \n",
       "66                                                                                                                                                                                                                                                                 \n",
       "67                                                                                                                                                                                                                                                                 \n",
       "68                                                                                                                                                                                                                                                                 \n",
       "69                                                                                                                                                                                                                                                                 \n",
       "70                                                                                                                                                                                                                                                                 \n",
       "71                                                                                                                                                                                                                                                                 \n",
       "72                                                                                                                                                                                                                                                                 \n",
       "73                                                                                                                                                                                                                                                                 \n",
       "74                                                                                                                                                                                                                                                                 \n",
       "75                                                                                                                                                                                                                                                                 \n",
       "76                                                                                                                                                                                                                                                                 \n",
       "77                                                                                                                                                                                                                                                                 \n",
       "78                                                                                                                                                                                                                                                                 \n",
       "\n",
       "Risk                                                                                                               Intellectual Property  \\\n",
       "0                         An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)   \n",
       "1                                                                                                                               BELEBELE   \n",
       "2                                                                            Big-bench: Low-resource language, Non-English, Translation    \n",
       "3                                                                       Big-bench: Social bias, Racial bias, Gender bias, Religious bias   \n",
       "4                                                                                                                    Big-bench: Toxicity   \n",
       "5                                                                                                                Big-bench: Truthfulness   \n",
       "6                                                                                                      C-Eval (Chinese evaluation suite)   \n",
       "7                                                                                                                DecodingTrust: Fairness   \n",
       "8                                                                                                          DecodingTrust: Machine Ethics   \n",
       "9                                                                                                         DecodingTrust: Stereotype Bias   \n",
       "10                                                                                                               DecodingTrust: Toxicity   \n",
       "11                                                                                                      Evaluation Harness: CrowS-Pairs    \n",
       "12                                                                                                            Evaluation Harness: ETHICS   \n",
       "13                                                                                                           Evaluation Harness: ToxiGen   \n",
       "14                                                              Finding New Biases in Language Models with a Holistic Descriptor Dataset   \n",
       "15    From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models   \n",
       "16                                                                                                                            HELM: Bias   \n",
       "17                                                                                                                       HELM: Copyright   \n",
       "18                                                                                                          HELM: Language (Twitter AAE)   \n",
       "19                                                                                                                        HELM: Toxicity   \n",
       "20                                                                                                                           LegalBench    \n",
       "21                                                                                                                               MASSIVE   \n",
       "22                                                                                MT-bench - Benchmarking (with human and model scoring)   \n",
       "23                                                                                                                         Mark My Words   \n",
       "24                                                                                   The Self-Perception and Political Biases of ChatGPT   \n",
       "25                                                 Towards Measuring the Representation of Subjective Global Opinions in Language Models   \n",
       "26                                                                                                                            llmprivacy   \n",
       "27                                                                                                                                 mimir   \n",
       "28                                                                                                                                         \n",
       "29                                                                                                                                         \n",
       "30                                                                                                                                         \n",
       "31                                                                                                                                         \n",
       "32                                                                                                                                         \n",
       "33                                                                                                                                         \n",
       "34                                                                                                                                         \n",
       "35                                                                                                                                         \n",
       "36                                                                                                                                         \n",
       "37                                                                                                                                         \n",
       "38                                                                                                                                         \n",
       "39                                                                                                                                         \n",
       "40                                                                                                                                         \n",
       "41                                                                                                                                         \n",
       "42                                                                                                                                         \n",
       "43                                                                                                                                         \n",
       "44                                                                                                                                         \n",
       "45                                                                                                                                         \n",
       "46                                                                                                                                         \n",
       "47                                                                                                                                         \n",
       "48                                                                                                                                         \n",
       "49                                                                                                                                         \n",
       "50                                                                                                                                         \n",
       "51                                                                                                                                         \n",
       "52                                                                                                                                         \n",
       "53                                                                                                                                         \n",
       "54                                                                                                                                         \n",
       "55                                                                                                                                         \n",
       "56                                                                                                                                         \n",
       "57                                                                                                                                         \n",
       "58                                                                                                                                         \n",
       "59                                                                                                                                         \n",
       "60                                                                                                                                         \n",
       "61                                                                                                                                         \n",
       "62                                                                                                                                         \n",
       "63                                                                                                                                         \n",
       "64                                                                                                                                         \n",
       "65                                                                                                                                         \n",
       "66                                                                                                                                         \n",
       "67                                                                                                                                         \n",
       "68                                                                                                                                         \n",
       "69                                                                                                                                         \n",
       "70                                                                                                                                         \n",
       "71                                                                                                                                         \n",
       "72                                                                                                                                         \n",
       "73                                                                                                                                         \n",
       "74                                                                                                                                         \n",
       "75                                                                                                                                         \n",
       "76                                                                                                                                         \n",
       "77                                                                                                                                         \n",
       "78                                                                                                                                         \n",
       "\n",
       "Risk                                                                                          Obscene, Degrading, and/or Abusive Content  \\\n",
       "0                                                                                                                               BELEBELE   \n",
       "1                                                                                                                 Big-bench: Convince Me   \n",
       "2                                                                            Big-bench: Low-resource language, Non-English, Translation    \n",
       "3                                                                       Big-bench: Social bias, Racial bias, Gender bias, Religious bias   \n",
       "4                                                                                                                    Big-bench: Toxicity   \n",
       "5                                                                                                                Big-bench: Truthfulness   \n",
       "6                                                                                                      C-Eval (Chinese evaluation suite)   \n",
       "7                                                                                                                DecodingTrust: Fairness   \n",
       "8                                                                                                         DecodingTrust: Stereotype Bias   \n",
       "9                                                                                                                DecodingTrust: Toxicity   \n",
       "10                                                                                                      Evaluation Harness: CrowS-Pairs    \n",
       "11                                                                                                           Evaluation Harness: ToxiGen   \n",
       "12                                                              Finding New Biases in Language Models with a Holistic Descriptor Dataset   \n",
       "13    From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models   \n",
       "14                                                                                                                            HELM: Bias   \n",
       "15                                                                                                          HELM: Language (Twitter AAE)   \n",
       "16                                                                                                            HELM: Reiteration, Wedging   \n",
       "17                                                                                                                        HELM: Toxicity   \n",
       "18                                                                                                                               MASSIVE   \n",
       "19                                                                                                                             MLCommons   \n",
       "20                                                                                MT-bench - Benchmarking (with human and model scoring)   \n",
       "21                                                                                                                         Mark My Words   \n",
       "22                                                                                   The Self-Perception and Political Biases of ChatGPT   \n",
       "23                                                                                                                    The WMDP Benchmark   \n",
       "24                                                 Towards Measuring the Representation of Subjective Global Opinions in Language Models   \n",
       "25                                                                                                                                         \n",
       "26                                                                                                                                         \n",
       "27                                                                                                                                         \n",
       "28                                                                                                                                         \n",
       "29                                                                                                                                         \n",
       "30                                                                                                                                         \n",
       "31                                                                                                                                         \n",
       "32                                                                                                                                         \n",
       "33                                                                                                                                         \n",
       "34                                                                                                                                         \n",
       "35                                                                                                                                         \n",
       "36                                                                                                                                         \n",
       "37                                                                                                                                         \n",
       "38                                                                                                                                         \n",
       "39                                                                                                                                         \n",
       "40                                                                                                                                         \n",
       "41                                                                                                                                         \n",
       "42                                                                                                                                         \n",
       "43                                                                                                                                         \n",
       "44                                                                                                                                         \n",
       "45                                                                                                                                         \n",
       "46                                                                                                                                         \n",
       "47                                                                                                                                         \n",
       "48                                                                                                                                         \n",
       "49                                                                                                                                         \n",
       "50                                                                                                                                         \n",
       "51                                                                                                                                         \n",
       "52                                                                                                                                         \n",
       "53                                                                                                                                         \n",
       "54                                                                                                                                         \n",
       "55                                                                                                                                         \n",
       "56                                                                                                                                         \n",
       "57                                                                                                                                         \n",
       "58                                                                                                                                         \n",
       "59                                                                                                                                         \n",
       "60                                                                                                                                         \n",
       "61                                                                                                                                         \n",
       "62                                                                                                                                         \n",
       "63                                                                                                                                         \n",
       "64                                                                                                                                         \n",
       "65                                                                                                                                         \n",
       "66                                                                                                                                         \n",
       "67                                                                                                                                         \n",
       "68                                                                                                                                         \n",
       "69                                                                                                                                         \n",
       "70                                                                                                                                         \n",
       "71                                                                                                                                         \n",
       "72                                                                                                                                         \n",
       "73                                                                                                                                         \n",
       "74                                                                                                                                         \n",
       "75                                                                                                                                         \n",
       "76                                                                                                                                         \n",
       "77                                                                                                                                         \n",
       "78                                                                                                                                         \n",
       "\n",
       "Risk                                                                                                                                                                                                                          Toxicity, Bias, and Homogenization  \\\n",
       "0                                                                                                                                                                                                                                                       BELEBELE   \n",
       "1     Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World   \n",
       "2                                                                                                                                                               Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity   \n",
       "3                                                                                                                                                                                                                     Big-bench: Context Free Question Answering   \n",
       "4                                                                                                                                                                           Big-bench: Contextual question answering, Reading comprehension, Question generation   \n",
       "5                                                                                                                                                                                                    Big-bench: Low-resource language, Non-English, Translation    \n",
       "6                                                                                                                                                                                                                         Big-bench: Morphology, Grammar, Syntax   \n",
       "7                                                                                                                                                                                                                                 Big-bench: Out-of-Distribution   \n",
       "8                                                                                                                                                                                                                                          Big-bench: Paraphrase   \n",
       "9                                                                                                                                                                                               Big-bench: Social bias, Racial bias, Gender bias, Religious bias   \n",
       "10                                                                                                                                                                                                                             Big-bench: Sufficient information   \n",
       "11                                                                                                                                                                                                                                      Big-bench: Summarization   \n",
       "12                                                                                                                                                                                                                                           Big-bench: Toxicity   \n",
       "13                                                                                                                                                                                                                             C-Eval (Chinese evaluation suite)   \n",
       "14                                                                                                                                                                                                                                       DecodingTrust: Fairness   \n",
       "15                                                                                                                           DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking   \n",
       "16                                                                                                                                                                                                                                DecodingTrust: Stereotype Bias   \n",
       "17                                                                                                                                                                                                                                       DecodingTrust: Toxicity   \n",
       "18                                                                                                                                                                                                                          Eval Gauntlet\\nReading comprehension   \n",
       "19                                                                                                                                                                                   Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming   \n",
       "20                                                                                                                                                                                                                        Eval Gauntlet: Language Understanding    \n",
       "21                                                                                                                                                                                                                                Eval Gauntlet: World Knowledge   \n",
       "22                                                                                                                                                                                                                                     Evaluation Harness: BLiMP   \n",
       "23                                                                                                                                                                                                                                 Evaluation Harness: CoQA, ARC   \n",
       "24                                                                                                                                                                                                                              Evaluation Harness: CrowS-Pairs    \n",
       "25                                                                                                                                                                                                                                      Evaluation Harness: GLUE   \n",
       "26                                                                                                                                                                                                         Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA   \n",
       "27                                                                                                                                                                                                                                    Evaluation Harness: MuTual   \n",
       "28                                                                                                                                                                                                Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP   \n",
       "29                                                                                                                                                                                                                                   Evaluation Harness: ToxiGen   \n",
       "30                                                                                                                                                               FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness   \n",
       "31                                                                                                                                                                                                               FLASK: Readability, Conciseness, Insightfulness   \n",
       "32                                                                                                                                                                                      Finding New Biases in Language Models with a Holistic Descriptor Dataset   \n",
       "33                                                                                                                            From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models   \n",
       "34                                                                                                                                                                                                                                                    HELM: Bias   \n",
       "35                                                                                                                                                                                                                                               HELM: Knowledge   \n",
       "36                                                                                                                                                                                                                                                HELM: Language   \n",
       "37                                                                                                                                                                                                                                  HELM: Language (Twitter AAE)   \n",
       "38                                                                                                                                                                                                                                      HELM: Question answering   \n",
       "39                                                                                                                                                                                                                                               HELM: Reasoning   \n",
       "40                                                                                                                                                                                                                             HELM: Robustness to contrast sets   \n",
       "41                                                                                                                                                                                                                                           HELM: Summarization   \n",
       "42                                                                                                                                                                                                                                     HELM: Text classification   \n",
       "43                                                                                                                                                                                                                                                HELM: Toxicity   \n",
       "44                                                                                                                                                                                                       Hugging Face: Fill-mask, Text generation - Benchmarking   \n",
       "45                                                                                                                                                                                                                              Hugging Face: Question answering   \n",
       "46                                                                                                                                                                                                                                   Hugging Face: Summarization   \n",
       "47                                                                                                                                                                             Hugging Face: Text classification, Token classification, Zero-shot classification   \n",
       "48                                                                                                                                                                                                                                                       MASSIVE   \n",
       "49                                                                                                                                                                                                                                                      MT-bench   \n",
       "50                                                                                                                                                                                                        MT-bench - Benchmarking (with human and model scoring)   \n",
       "51                                                                                                                                                                                                           The Self-Perception and Political Biases of ChatGPT   \n",
       "52                                                                                                                                                                         Towards Measuring the Representation of Subjective Global Opinions in Language Models   \n",
       "53                                                                                                                                                                                                                                                                 \n",
       "54                                                                                                                                                                                                                                                                 \n",
       "55                                                                                                                                                                                                                                                                 \n",
       "56                                                                                                                                                                                                                                                                 \n",
       "57                                                                                                                                                                                                                                                                 \n",
       "58                                                                                                                                                                                                                                                                 \n",
       "59                                                                                                                                                                                                                                                                 \n",
       "60                                                                                                                                                                                                                                                                 \n",
       "61                                                                                                                                                                                                                                                                 \n",
       "62                                                                                                                                                                                                                                                                 \n",
       "63                                                                                                                                                                                                                                                                 \n",
       "64                                                                                                                                                                                                                                                                 \n",
       "65                                                                                                                                                                                                                                                                 \n",
       "66                                                                                                                                                                                                                                                                 \n",
       "67                                                                                                                                                                                                                                                                 \n",
       "68                                                                                                                                                                                                                                                                 \n",
       "69                                                                                                                                                                                                                                                                 \n",
       "70                                                                                                                                                                                                                                                                 \n",
       "71                                                                                                                                                                                                                                                                 \n",
       "72                                                                                                                                                                                                                                                                 \n",
       "73                                                                                                                                                                                                                                                                 \n",
       "74                                                                                                                                                                                                                                                                 \n",
       "75                                                                                                                                                                                                                                                                 \n",
       "76                                                                                                                                                                                                                                                                 \n",
       "77                                                                                                                                                                                                                                                                 \n",
       "78                                                                                                                                                                                                                                                                 \n",
       "\n",
       "Risk                                                                                                                                                                                                                       Value Chain and Component Integration  \n",
       "0                                                                                                                                                 An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B)  \n",
       "1                                                                                                                                                                                                                                                       BELEBELE  \n",
       "2     Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World  \n",
       "3                                                                                                                                                               Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity  \n",
       "4                                                                                                                                                                                                                     Big-bench: Context Free Question Answering  \n",
       "5                                                                                                                                                                           Big-bench: Contextual question answering, Reading comprehension, Question generation  \n",
       "6                                                                                                                                                                                                                                         Big-bench: Convince Me  \n",
       "7                                                                                                                                                                                                    Big-bench: Low-resource language, Non-English, Translation   \n",
       "8                                                                                                                                                                                                                         Big-bench: Morphology, Grammar, Syntax  \n",
       "9                                                                                                                                                                                                                                 Big-bench: Out-of-Distribution  \n",
       "10                                                                                                                                                                                                                                         Big-bench: Paraphrase  \n",
       "11                                                                                                                                                                                              Big-bench: Social bias, Racial bias, Gender bias, Religious bias  \n",
       "12                                                                                                                                                                                                                             Big-bench: Sufficient information  \n",
       "13                                                                                                                                                                                                                                      Big-bench: Summarization  \n",
       "14                                                                                                                                                                                                                                           Big-bench: Toxicity  \n",
       "15                                                                                                                                                                                                                                       Big-bench: Truthfulness  \n",
       "16                                                                                                                                                                                                                             C-Eval (Chinese evaluation suite)  \n",
       "17                                                                                                                                                                                          Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation  \n",
       "18                                                                                                                                                                          DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations  \n",
       "19                                                                                                                                                                                                                                       DecodingTrust: Fairness  \n",
       "20                                                                                                                                                                                                                                 DecodingTrust: Machine Ethics  \n",
       "21                                                                                                                           DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking  \n",
       "22                                                                                                                                                                                                                                DecodingTrust: Stereotype Bias  \n",
       "23                                                                                                                                                                                                                                       DecodingTrust: Toxicity  \n",
       "24                                                                                                                                                                                                                          Eval Gauntlet\\nReading comprehension  \n",
       "25                                                                                                                                                                                   Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming  \n",
       "26                                                                                                                                                                                                                        Eval Gauntlet: Language Understanding   \n",
       "27                                                                                                                                                                                                                                Eval Gauntlet: World Knowledge  \n",
       "28                                                                                                                                                                                                                                     Evaluation Harness: BLiMP  \n",
       "29                                                                                                                                                                                                                                 Evaluation Harness: CoQA, ARC  \n",
       "30                                                                                                                                                                                                                              Evaluation Harness: CrowS-Pairs   \n",
       "31                                                                                                                                                                                                                                    Evaluation Harness: ETHICS  \n",
       "32                                                                                                                                                                                                                                      Evaluation Harness: GLUE  \n",
       "33                                                                                                                                                                                                         Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA  \n",
       "34                                                                                                                                                                                                                                    Evaluation Harness: MuTual  \n",
       "35                                                                                                                                                                                                Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP  \n",
       "36                                                                                                                                                                                                                                   Evaluation Harness: ToxiGen  \n",
       "37                                                                                                                                                               FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness  \n",
       "38                                                                                                                                                                                                               FLASK: Readability, Conciseness, Insightfulness  \n",
       "39                                                                                                                                                                                      Finding New Biases in Language Models with a Holistic Descriptor Dataset  \n",
       "40                                                                                                                            From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models  \n",
       "41                                                                                                                                                                                                                                                    HELM: Bias  \n",
       "42                                                                                                                                                                                                                                               HELM: Copyright  \n",
       "43                                                                                                                                                                                                                                               HELM: Knowledge  \n",
       "44                                                                                                                                                                                                                                                HELM: Language  \n",
       "45                                                                                                                                                                                                                                  HELM: Language (Twitter AAE)  \n",
       "46                                                                                                                                                                                                                                      HELM: Question answering  \n",
       "47                                                                                                                                                                                                                                               HELM: Reasoning  \n",
       "48                                                                                                                                                                                                                                    HELM: Reiteration, Wedging  \n",
       "49                                                                                                                                                                                                                             HELM: Robustness to contrast sets  \n",
       "50                                                                                                                                                                                                                                           HELM: Summarization  \n",
       "51                                                                                                                                                                                                                                     HELM: Text classification  \n",
       "52                                                                                                                                                                                                                                                HELM: Toxicity  \n",
       "53                                                                                                                                                                                                       Hugging Face: Fill-mask, Text generation - Benchmarking  \n",
       "54                                                                                                                                                                                                                              Hugging Face: Question answering  \n",
       "55                                                                                                                                                                                                                                   Hugging Face: Summarization  \n",
       "56                                                                                                                                                                             Hugging Face: Text classification, Token classification, Zero-shot classification  \n",
       "57                                                                                                                                                                                                                         In-The-Wild Jailbreak Prompts on LLMs  \n",
       "58                                                                                                                                                                                                                                            JailbreakingLLMs\\n  \n",
       "59                                                                                                                                                                                                                                                   LegalBench   \n",
       "60                                                                                                                                                                                                                                                       MASSIVE  \n",
       "61                                                                                                                                                                                                                                                     MLCommons  \n",
       "62                                                                                                                                                                                                                                                      MT-bench  \n",
       "63                                                                                                                                                                                                        MT-bench - Benchmarking (with human and model scoring)  \n",
       "64                                                                                                                                                                                                                                                 Mark My Words  \n",
       "65                                                                                                                                                                                        TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack  \n",
       "66                                                                                                                                                                                                           The Self-Perception and Political Biases of ChatGPT  \n",
       "67                                                                                                                                                                                                                                            The WMDP Benchmark  \n",
       "68                                                                                                                                                                         Towards Measuring the Representation of Subjective Global Opinions in Language Models  \n",
       "69                                                                                                                                                                                                                                          detect-pretrain-code  \n",
       "70                                                                                                                                                                                                                                                    llmprivacy  \n",
       "71                                                                                                                                                                                                                                                         mimir  \n",
       "72                                                                                                                                                                                                                                                                \n",
       "73                                                                                                                                                                                                                                                                \n",
       "74                                                                                                                                                                                                                                                                \n",
       "75                                                                                                                                                                                                                                                                \n",
       "76                                                                                                                                                                                                                                                                \n",
       "77                                                                                                                                                                                                                                                                \n",
       "78                                                                                                                                                                                                                                                                "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_risk_measure_by_gai_risk_frame = pd.DataFrame(columns=data_dict['gai_risk']['Risk'], index=range(0, 79))\n",
    "\n",
    "for j, risk in enumerate(low_risk_measure_by_gai_risk_frame.columns):\n",
    "    for i, eval_ in enumerate(list(intermediate_dict[risk])):     \n",
    "        low_risk_measure_by_gai_risk_frame.iloc[i, j] = eval_\n",
    "    if low_risk_measure_by_gai_risk_frame[risk].isnull().any().any():\n",
    "            low_risk_measure_by_gai_risk_frame[risk] = low_risk_measure_by_gai_risk_frame[risk].replace(np.nan, '')\n",
    "\n",
    "low_risk_measure_by_gai_risk_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b829c538-186b-41c5-9d86-dd6b9260d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "CBRN Information \\\\\n",
      "\\midrule\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "MLCommons \\\\\n",
      "Mark My Words \\\\\n",
      "The WMDP Benchmark \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Confabulation \\\\\n",
      "\\midrule\n",
      "BELEBELE \\\\\n",
      "Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World \\\\\n",
      "Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity \\\\\n",
      "Big-bench: Context Free Question Answering \\\\\n",
      "Big-bench: Contextual question answering, Reading comprehension, Question generation \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Morphology, Grammar, Syntax \\\\\n",
      "Big-bench: Out-of-Distribution \\\\\n",
      "Big-bench: Paraphrase \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Sufficient information \\\\\n",
      "Big-bench: Summarization \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "Eval Gauntlet\n",
      "Reading comprehension \\\\\n",
      "Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming \\\\\n",
      "Eval Gauntlet: Language Understanding  \\\\\n",
      "Eval Gauntlet: World Knowledge \\\\\n",
      "Evaluation Harness: BLiMP \\\\\n",
      "Evaluation Harness: CoQA, ARC \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: GLUE \\\\\n",
      "Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA \\\\\n",
      "Evaluation Harness: MuTual \\\\\n",
      "Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness \\\\\n",
      "FLASK: Readability, Conciseness, Insightfulness \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Knowledge \\\\\n",
      "HELM: Language \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Question answering \\\\\n",
      "HELM: Reasoning \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "HELM: Robustness to contrast sets \\\\\n",
      "HELM: Summarization \\\\\n",
      "HELM: Text classification \\\\\n",
      "HELM: Toxicity \\\\\n",
      "Hugging Face: Fill-mask, Text generation - Benchmarking \\\\\n",
      "Hugging Face: Question answering \\\\\n",
      "Hugging Face: Summarization \\\\\n",
      "Hugging Face: Text classification, Token classification, Zero-shot classification \\\\\n",
      "MASSIVE \\\\\n",
      "MLCommons \\\\\n",
      "MT-bench \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "Mark My Words \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Dangerous or Violent Recommendations \\\\\n",
      "\\midrule\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation \\\\\n",
      "DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "In-The-Wild Jailbreak Prompts on LLMs \\\\\n",
      "JailbreakingLLMs\n",
      " \\\\\n",
      "MLCommons \\\\\n",
      "Mark My Words \\\\\n",
      "TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "detect-pretrain-code \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Data Privacy \\\\\n",
      "\\midrule\n",
      "An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B) \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation \\\\\n",
      "DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations \\\\\n",
      "DecodingTrust: Machine Ethics \\\\\n",
      "Evaluation Harness: ETHICS \\\\\n",
      "HELM: Copyright \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "In-The-Wild Jailbreak Prompts on LLMs \\\\\n",
      "JailbreakingLLMs\n",
      " \\\\\n",
      "LegalBench  \\\\\n",
      "MLCommons \\\\\n",
      "Mark My Words \\\\\n",
      "TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "detect-pretrain-code \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Environmental \\\\\n",
      "\\midrule\n",
      "An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B) \\\\\n",
      "BELEBELE \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Machine Ethics \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: ETHICS \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Copyright \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "HELM: Toxicity \\\\\n",
      "LegalBench  \\\\\n",
      "MASSIVE \\\\\n",
      "MLCommons \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "Mark My Words \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Human-AI Configuration \\\\\n",
      "\\midrule\n",
      "An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B) \\\\\n",
      "BELEBELE \\\\\n",
      "Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World \\\\\n",
      "Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity \\\\\n",
      "Big-bench: Context Free Question Answering \\\\\n",
      "Big-bench: Contextual question answering, Reading comprehension, Question generation \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Morphology, Grammar, Syntax \\\\\n",
      "Big-bench: Out-of-Distribution \\\\\n",
      "Big-bench: Paraphrase \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Sufficient information \\\\\n",
      "Big-bench: Summarization \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation \\\\\n",
      "DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Machine Ethics \\\\\n",
      "DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "Eval Gauntlet\n",
      "Reading comprehension \\\\\n",
      "Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming \\\\\n",
      "Eval Gauntlet: Language Understanding  \\\\\n",
      "Eval Gauntlet: World Knowledge \\\\\n",
      "Evaluation Harness: BLiMP \\\\\n",
      "Evaluation Harness: CoQA, ARC \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: ETHICS \\\\\n",
      "Evaluation Harness: GLUE \\\\\n",
      "Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA \\\\\n",
      "Evaluation Harness: MuTual \\\\\n",
      "Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness \\\\\n",
      "FLASK: Readability, Conciseness, Insightfulness \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Copyright \\\\\n",
      "HELM: Knowledge \\\\\n",
      "HELM: Language \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Question answering \\\\\n",
      "HELM: Reasoning \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "HELM: Robustness to contrast sets \\\\\n",
      "HELM: Summarization \\\\\n",
      "HELM: Text classification \\\\\n",
      "HELM: Toxicity \\\\\n",
      "Hugging Face: Fill-mask, Text generation - Benchmarking \\\\\n",
      "Hugging Face: Question answering \\\\\n",
      "Hugging Face: Summarization \\\\\n",
      "Hugging Face: Text classification, Token classification, Zero-shot classification \\\\\n",
      "In-The-Wild Jailbreak Prompts on LLMs \\\\\n",
      "JailbreakingLLMs\n",
      " \\\\\n",
      "LegalBench  \\\\\n",
      "MASSIVE \\\\\n",
      "MLCommons \\\\\n",
      "MT-bench \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "Mark My Words \\\\\n",
      "TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      "detect-pretrain-code \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Information Integrity \\\\\n",
      "\\midrule\n",
      "An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B) \\\\\n",
      "Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World \\\\\n",
      "Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity \\\\\n",
      "Big-bench: Context Free Question Answering \\\\\n",
      "Big-bench: Contextual question answering, Reading comprehension, Question generation \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Morphology, Grammar, Syntax \\\\\n",
      "Big-bench: Out-of-Distribution \\\\\n",
      "Big-bench: Paraphrase \\\\\n",
      "Big-bench: Sufficient information \\\\\n",
      "Big-bench: Summarization \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "DecodingTrust: Machine Ethics \\\\\n",
      "DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking \\\\\n",
      "Eval Gauntlet\n",
      "Reading comprehension \\\\\n",
      "Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming \\\\\n",
      "Eval Gauntlet: Language Understanding  \\\\\n",
      "Eval Gauntlet: World Knowledge \\\\\n",
      "Evaluation Harness: BLiMP \\\\\n",
      "Evaluation Harness: CoQA, ARC \\\\\n",
      "Evaluation Harness: ETHICS \\\\\n",
      "Evaluation Harness: GLUE \\\\\n",
      "Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA \\\\\n",
      "Evaluation Harness: MuTual \\\\\n",
      "Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP \\\\\n",
      "FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness \\\\\n",
      "FLASK: Readability, Conciseness, Insightfulness \\\\\n",
      "HELM: Copyright \\\\\n",
      "HELM: Knowledge \\\\\n",
      "HELM: Language \\\\\n",
      "HELM: Question answering \\\\\n",
      "HELM: Reasoning \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "HELM: Robustness to contrast sets \\\\\n",
      "HELM: Summarization \\\\\n",
      "HELM: Text classification \\\\\n",
      "Hugging Face: Fill-mask, Text generation - Benchmarking \\\\\n",
      "Hugging Face: Question answering \\\\\n",
      "Hugging Face: Summarization \\\\\n",
      "Hugging Face: Text classification, Token classification, Zero-shot classification \\\\\n",
      "LegalBench  \\\\\n",
      "MLCommons \\\\\n",
      "MT-bench \\\\\n",
      "Mark My Words \\\\\n",
      "The WMDP Benchmark \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Information Security \\\\\n",
      "\\midrule\n",
      "Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World \\\\\n",
      "Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity \\\\\n",
      "Big-bench: Context Free Question Answering \\\\\n",
      "Big-bench: Contextual question answering, Reading comprehension, Question generation \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Morphology, Grammar, Syntax \\\\\n",
      "Big-bench: Out-of-Distribution \\\\\n",
      "Big-bench: Paraphrase \\\\\n",
      "Big-bench: Sufficient information \\\\\n",
      "Big-bench: Summarization \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation \\\\\n",
      "DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations \\\\\n",
      "DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking \\\\\n",
      "Eval Gauntlet\n",
      "Reading comprehension \\\\\n",
      "Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming \\\\\n",
      "Eval Gauntlet: Language Understanding  \\\\\n",
      "Eval Gauntlet: World Knowledge \\\\\n",
      "Evaluation Harness: BLiMP \\\\\n",
      "Evaluation Harness: CoQA, ARC \\\\\n",
      "Evaluation Harness: GLUE \\\\\n",
      "Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA \\\\\n",
      "Evaluation Harness: MuTual \\\\\n",
      "Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP \\\\\n",
      "FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness \\\\\n",
      "FLASK: Readability, Conciseness, Insightfulness \\\\\n",
      "HELM: Copyright \\\\\n",
      "HELM: Knowledge \\\\\n",
      "HELM: Language \\\\\n",
      "HELM: Question answering \\\\\n",
      "HELM: Reasoning \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "HELM: Robustness to contrast sets \\\\\n",
      "HELM: Summarization \\\\\n",
      "HELM: Text classification \\\\\n",
      "Hugging Face: Fill-mask, Text generation - Benchmarking \\\\\n",
      "Hugging Face: Question answering \\\\\n",
      "Hugging Face: Summarization \\\\\n",
      "Hugging Face: Text classification, Token classification, Zero-shot classification \\\\\n",
      "In-The-Wild Jailbreak Prompts on LLMs \\\\\n",
      "JailbreakingLLMs\n",
      " \\\\\n",
      "MLCommons \\\\\n",
      "MT-bench \\\\\n",
      "Mark My Words \\\\\n",
      "TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "detect-pretrain-code \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Intellectual Property \\\\\n",
      "\\midrule\n",
      "An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B) \\\\\n",
      "BELEBELE \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Machine Ethics \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: ETHICS \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Copyright \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Toxicity \\\\\n",
      "LegalBench  \\\\\n",
      "MASSIVE \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "Mark My Words \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Obscene, Degrading, and/or Abusive Content \\\\\n",
      "\\midrule\n",
      "BELEBELE \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "HELM: Toxicity \\\\\n",
      "MASSIVE \\\\\n",
      "MLCommons \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "Mark My Words \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Toxicity, Bias, and Homogenization \\\\\n",
      "\\midrule\n",
      "BELEBELE \\\\\n",
      "Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World \\\\\n",
      "Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity \\\\\n",
      "Big-bench: Context Free Question Answering \\\\\n",
      "Big-bench: Contextual question answering, Reading comprehension, Question generation \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Morphology, Grammar, Syntax \\\\\n",
      "Big-bench: Out-of-Distribution \\\\\n",
      "Big-bench: Paraphrase \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Sufficient information \\\\\n",
      "Big-bench: Summarization \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "Eval Gauntlet\n",
      "Reading comprehension \\\\\n",
      "Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming \\\\\n",
      "Eval Gauntlet: Language Understanding  \\\\\n",
      "Eval Gauntlet: World Knowledge \\\\\n",
      "Evaluation Harness: BLiMP \\\\\n",
      "Evaluation Harness: CoQA, ARC \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: GLUE \\\\\n",
      "Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA \\\\\n",
      "Evaluation Harness: MuTual \\\\\n",
      "Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness \\\\\n",
      "FLASK: Readability, Conciseness, Insightfulness \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Knowledge \\\\\n",
      "HELM: Language \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Question answering \\\\\n",
      "HELM: Reasoning \\\\\n",
      "HELM: Robustness to contrast sets \\\\\n",
      "HELM: Summarization \\\\\n",
      "HELM: Text classification \\\\\n",
      "HELM: Toxicity \\\\\n",
      "Hugging Face: Fill-mask, Text generation - Benchmarking \\\\\n",
      "Hugging Face: Question answering \\\\\n",
      "Hugging Face: Summarization \\\\\n",
      "Hugging Face: Text classification, Token classification, Zero-shot classification \\\\\n",
      "MASSIVE \\\\\n",
      "MT-bench \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Value Chain and Component Integration \\\\\n",
      "\\midrule\n",
      "An Evaluation on Large Language Model Outputs: Discourse and Memorization (with human scoring, see Appendix B) \\\\\n",
      "BELEBELE \\\\\n",
      "Big-bench: Algorithms, Logical reasoning, Implicit reasoning, Mathematics, Arithmetic, Algebra, Mathematical proof, Fallacy, Negation, Computer code, Probabilistic reasoning, Social reasoning, Analogical reasoning, Multi-step, Understanding the World \\\\\n",
      "Big-bench: Analytic entailment, Formal fallacies and syllogisms with negation, Entailed polarity \\\\\n",
      "Big-bench: Context Free Question Answering \\\\\n",
      "Big-bench: Contextual question answering, Reading comprehension, Question generation \\\\\n",
      "Big-bench: Convince Me \\\\\n",
      "Big-bench: Low-resource language, Non-English, Translation  \\\\\n",
      "Big-bench: Morphology, Grammar, Syntax \\\\\n",
      "Big-bench: Out-of-Distribution \\\\\n",
      "Big-bench: Paraphrase \\\\\n",
      "Big-bench: Social bias, Racial bias, Gender bias, Religious bias \\\\\n",
      "Big-bench: Sufficient information \\\\\n",
      "Big-bench: Summarization \\\\\n",
      "Big-bench: Toxicity \\\\\n",
      "Big-bench: Truthfulness \\\\\n",
      "C-Eval (Chinese evaluation suite) \\\\\n",
      "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation \\\\\n",
      "DecodingTrust: Adversarial Robustness, Robustness Against Adversarial Demonstrations \\\\\n",
      "DecodingTrust: Fairness \\\\\n",
      "DecodingTrust: Machine Ethics \\\\\n",
      "DecodingTrust: Out-of-Distribution Robustness, Adversarial Robustness, Robustness Against Adversarial Demonstrations - Benchmarking \\\\\n",
      "DecodingTrust: Stereotype Bias \\\\\n",
      "DecodingTrust: Toxicity \\\\\n",
      "Eval Gauntlet\n",
      "Reading comprehension \\\\\n",
      "Eval Gauntlet: Commonsense reasoning, Symbolic problem solving, Programming \\\\\n",
      "Eval Gauntlet: Language Understanding  \\\\\n",
      "Eval Gauntlet: World Knowledge \\\\\n",
      "Evaluation Harness: BLiMP \\\\\n",
      "Evaluation Harness: CoQA, ARC \\\\\n",
      "Evaluation Harness: CrowS-Pairs  \\\\\n",
      "Evaluation Harness: ETHICS \\\\\n",
      "Evaluation Harness: GLUE \\\\\n",
      "Evaluation Harness: HellaSwag, OpenBookQA, TruthfulQA \\\\\n",
      "Evaluation Harness: MuTual \\\\\n",
      "Evaluation Harness: PIQA, PROST, MC-TACO, MathQA, LogiQA, DROP \\\\\n",
      "Evaluation Harness: ToxiGen \\\\\n",
      "FLASK: Logical correctness, Logical robustness, Logical efficiency, Comprehension, Completeness \\\\\n",
      "FLASK: Readability, Conciseness, Insightfulness \\\\\n",
      "Finding New Biases in Language Models with a Holistic Descriptor Dataset \\\\\n",
      "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models \\\\\n",
      "HELM: Bias \\\\\n",
      "HELM: Copyright \\\\\n",
      "HELM: Knowledge \\\\\n",
      "HELM: Language \\\\\n",
      "HELM: Language (Twitter AAE) \\\\\n",
      "HELM: Question answering \\\\\n",
      "HELM: Reasoning \\\\\n",
      "HELM: Reiteration, Wedging \\\\\n",
      "HELM: Robustness to contrast sets \\\\\n",
      "HELM: Summarization \\\\\n",
      "HELM: Text classification \\\\\n",
      "HELM: Toxicity \\\\\n",
      "Hugging Face: Fill-mask, Text generation - Benchmarking \\\\\n",
      "Hugging Face: Question answering \\\\\n",
      "Hugging Face: Summarization \\\\\n",
      "Hugging Face: Text classification, Token classification, Zero-shot classification \\\\\n",
      "In-The-Wild Jailbreak Prompts on LLMs \\\\\n",
      "JailbreakingLLMs\n",
      " \\\\\n",
      "LegalBench  \\\\\n",
      "MASSIVE \\\\\n",
      "MLCommons \\\\\n",
      "MT-bench \\\\\n",
      "MT-bench - Benchmarking (with human and model scoring) \\\\\n",
      "Mark My Words \\\\\n",
      "TAP: A Query-Efficient Method for Jailbreaking Black-Box LLMs - Attack \\\\\n",
      "The Self-Perception and Political Biases of ChatGPT \\\\\n",
      "The WMDP Benchmark \\\\\n",
      "Towards Measuring the Representation of Subjective Global Opinions in Language Models \\\\\n",
      "detect-pretrain-code \\\\\n",
      "llmprivacy \\\\\n",
      "mimir \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for risk in low_risk_measure_by_gai_risk_frame.columns:\n",
    "    print(low_risk_measure_by_gai_risk_frame[risk].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d3da1-7818-4347-818c-9c654f28b94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
