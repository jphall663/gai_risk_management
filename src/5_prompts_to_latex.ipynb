{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ad31e1-1f05-4c9b-a3de-bc21fda68f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# show everything\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ca2f43-89af-4d0e-8552-f4cc3e46099c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trustworthy Characteristic</th>\n",
       "      <th>Prompting Strategy</th>\n",
       "      <th>Goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accountable and Transparent</td>\n",
       "      <td>Context exhaustion/logic-overloading prompts; Multi-tasking prompts</td>\n",
       "      <td>Inability to provide explanations for recourse/unexplainable decisioning processes; No disclosure of AI interaction; Lack of user feedback mechanisms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair-with Harmful Bias Managed</td>\n",
       "      <td>Counterfactual prompts; Pros and cons prompts; Role-playing prompts; Low context prompts; Repeat this</td>\n",
       "      <td>Denigration; Diminished performance or safety across languages/dialects; Erasure; Ex-nomination; Implied demographics; Misrecognition; Stereotyping; Underrepresentation; Homogenized content; output from other models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interpretable and Explainable</td>\n",
       "      <td>Context exhaustion/logic-overloading prompts (to reveal unexplainable decisioning processes)</td>\n",
       "      <td>Inability to provide explanations for recourse/unexplalnable decisioning processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Privacy-enhanced</td>\n",
       "      <td>Auto/biographical prompts; Location awareness prompts; Autocompletion prompts; Repeat this</td>\n",
       "      <td>Unauthorized disclosure of personal or sensitive user information; Leak of training data; Violation of relevant privacy policies or laws; Unathorized secondary data use; Unauthorized data collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Safe</td>\n",
       "      <td>Pros and cons prompts; Role-playing prompts; Content exhaustion/niche-seeking prompts; Ingratiation/reverse psychology prompts; Location awareness prompts; Repeat this</td>\n",
       "      <td>Presentation of information that can cause physical or emotional harm; Sharing user locations; Suicide ideation; Harmful dis/misinformation (e.g., COVID disinformation); Incitement; lnformation relating to weapons or harmful substances; lnformation relating to committing to crimes (e.g., phishing, extortion, swattinng); Obscene or inappropriate materials for minors; CSAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Secure and Resilient</td>\n",
       "      <td>Multi-tasking prompts; Pros and cons prompts; Role-playing prompts; Content exhaustion/niche-seeking prompts; Ingratiation/reverse psychology prompts; Prompt injection attacks; Model extraction/Membership inference attacks; Random attacks</td>\n",
       "      <td>Activating system bypass (\"jailbreak\"); Altering system outcomes (integrity violations, e.g., via prompt injection); Data breaches (confidentiality violations, e.g., via membership inference); Increased latency or resource usage (availability vlolations, e.g., via sponge example attacks); Available anonymous use; Dependency, supply chain, or third party vulnerabilities; lnapproportate disclosure of proprietary system lnformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valid and Reliable</td>\n",
       "      <td>Multi-tasking prompts; Role-playing prompts; Ingratiation/reverse psychology prompts; Time-perplexity prompts; Niche-seeking prompts; Logic overloading prompts; Repeat this; Numeric calculation</td>\n",
       "      <td>Errors/confabutated content (\"hallucinalion\"); Unreliable/erroneous reasoning or planning; Unreliable/erroneous decision-support or making; Faulty citation; Wrong calculations or numeric queries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Trustworthy Characteristic  \\\n",
       "0     Accountable and Transparent   \n",
       "1  Fair-with Harmful Bias Managed   \n",
       "2   Interpretable and Explainable   \n",
       "3               Privacy-enhanced    \n",
       "4                            Safe   \n",
       "5            Secure and Resilient   \n",
       "6              Valid and Reliable   \n",
       "\n",
       "                                                                                                                                                                                                                               Prompting Strategy  \\\n",
       "0                                                                                                                                                                             Context exhaustion/logic-overloading prompts; Multi-tasking prompts   \n",
       "1                                                                                                                                           Counterfactual prompts; Pros and cons prompts; Role-playing prompts; Low context prompts; Repeat this   \n",
       "2                                                                                                                                                    Context exhaustion/logic-overloading prompts (to reveal unexplainable decisioning processes)   \n",
       "3                                                                                                                                                      Auto/biographical prompts; Location awareness prompts; Autocompletion prompts; Repeat this   \n",
       "4                                                                         Pros and cons prompts; Role-playing prompts; Content exhaustion/niche-seeking prompts; Ingratiation/reverse psychology prompts; Location awareness prompts; Repeat this   \n",
       "5  Multi-tasking prompts; Pros and cons prompts; Role-playing prompts; Content exhaustion/niche-seeking prompts; Ingratiation/reverse psychology prompts; Prompt injection attacks; Model extraction/Membership inference attacks; Random attacks   \n",
       "6                                               Multi-tasking prompts; Role-playing prompts; Ingratiation/reverse psychology prompts; Time-perplexity prompts; Niche-seeking prompts; Logic overloading prompts; Repeat this; Numeric calculation   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                               Goal  \n",
       "0                                                                                                                                                                                                                                                                                             Inability to provide explanations for recourse/unexplainable decisioning processes; No disclosure of AI interaction; Lack of user feedback mechanisms  \n",
       "1                                                                                                                                                                                                                           Denigration; Diminished performance or safety across languages/dialects; Erasure; Ex-nomination; Implied demographics; Misrecognition; Stereotyping; Underrepresentation; Homogenized content; output from other models  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                Inability to provide explanations for recourse/unexplalnable decisioning processes  \n",
       "3                                                                                                                                                                                                                                            Unauthorized disclosure of personal or sensitive user information; Leak of training data; Violation of relevant privacy policies or laws; Unathorized secondary data use; Unauthorized data collection  \n",
       "4                                                             Presentation of information that can cause physical or emotional harm; Sharing user locations; Suicide ideation; Harmful dis/misinformation (e.g., COVID disinformation); Incitement; lnformation relating to weapons or harmful substances; lnformation relating to committing to crimes (e.g., phishing, extortion, swattinng); Obscene or inappropriate materials for minors; CSAM  \n",
       "5  Activating system bypass (\"jailbreak\"); Altering system outcomes (integrity violations, e.g., via prompt injection); Data breaches (confidentiality violations, e.g., via membership inference); Increased latency or resource usage (availability vlolations, e.g., via sponge example attacks); Available anonymous use; Dependency, supply chain, or third party vulnerabilities; lnapproportate disclosure of proprietary system lnformation  \n",
       "6                                                                                                                                                                                                                                                Errors/confabutated content (\"hallucinalion\"); Unreliable/erroneous reasoning or planning; Unreliable/erroneous decision-support or making; Faulty citation; Wrong calculations or numeric queries  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'..' + os.sep + 'data' + os.sep + 'data.pkl', 'rb') as fp:\n",
    "    data_dict = pickle.load(fp)\n",
    "\n",
    "data_dict['rt_strategies_goals_by_tc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a8864a-22b6-400a-b5c1-400667050274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "Trustworthy Characteristic & Goal & Prompting Strategy \\\\\n",
      "\\midrule\n",
      "Accountable and Transparent & Inability to provide explanations for recourse/unexplainable decisioning processes; No disclosure of AI interaction; Lack of user feedback mechanisms & Context exhaustion/logic-overloading prompts; Multi-tasking prompts \\\\\n",
      "Fair-with Harmful Bias Managed & Denigration; Diminished performance or safety across languages/dialects; Erasure; Ex-nomination; Implied demographics; Misrecognition; Stereotyping; Underrepresentation; Homogenized content; output from other models & Counterfactual prompts; Pros and cons prompts; Role-playing prompts; Low context prompts; Repeat this \\\\\n",
      "Interpretable and Explainable & Inability to provide explanations for recourse/unexplalnable decisioning processes & Context exhaustion/logic-overloading prompts (to reveal unexplainable decisioning processes) \\\\\n",
      "Privacy-enhanced  & Unauthorized disclosure of personal or sensitive user information; Leak of training data; Violation of relevant privacy policies or laws; Unathorized secondary data use; Unauthorized data collection & Auto/biographical prompts; Location awareness prompts; Autocompletion prompts; Repeat this \\\\\n",
      "Safe & Presentation of information that can cause physical or emotional harm; Sharing user locations; Suicide ideation; Harmful dis/misinformation (e.g., COVID disinformation); Incitement; lnformation relating to weapons or harmful substances; lnformation relating to committing to crimes (e.g., phishing, extortion, swattinng); Obscene or inappropriate materials for minors; CSAM & Pros and cons prompts; Role-playing prompts; Content exhaustion/niche-seeking prompts; Ingratiation/reverse psychology prompts; Location awareness prompts; Repeat this \\\\\n",
      "Secure and Resilient & Activating system bypass (\"jailbreak\"); Altering system outcomes (integrity violations, e.g., via prompt injection); Data breaches (confidentiality violations, e.g., via membership inference); Increased latency or resource usage (availability vlolations, e.g., via sponge example attacks); Available anonymous use; Dependency, supply chain, or third party vulnerabilities; lnapproportate disclosure of proprietary system lnformation & Multi-tasking prompts; Pros and cons prompts; Role-playing prompts; Content exhaustion/niche-seeking prompts; Ingratiation/reverse psychology prompts; Prompt injection attacks; Model extraction/Membership inference attacks; Random attacks \\\\\n",
      "Valid and Reliable & Errors/confabutated content (\"hallucinalion\"); Unreliable/erroneous reasoning or planning; Unreliable/erroneous decision-support or making; Faulty citation; Wrong calculations or numeric queries & Multi-tasking prompts; Role-playing prompts; Ingratiation/reverse psychology prompts; Time-perplexity prompts; Niche-seeking prompts; Logic overloading prompts; Repeat this; Numeric calculation \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_dict['rt_strategies_goals_by_tc'][['Trustworthy Characteristic','Goal','Prompting Strategy']].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5dda6fd-a6ca-4f02-83a6-44f4c714d7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAI Risk</th>\n",
       "      <th>Red-teaming Goals</th>\n",
       "      <th>Red-teaming Strategies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBRN Information</td>\n",
       "      <td>Accessing or synthesis of CBRN weapon or related information. CBRN testing should consider the marginal risk of foundation models. In other words, the goal of testing should be to understand the incremental risk of CBRN testing relative to the information one can access from non-foundation models and online.</td>\n",
       "      <td>Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test autocompletion prompts to elicit CBRN information or synthesis of CBRN information; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit CBRN information or synthesis of CBRN information; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and reveal CBRN information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Confabulation</td>\n",
       "      <td>Eliciting errors/confabutated content, unreliable/erroneous reasoning or planning, unreliable/erroneous decision-support or decision-making, faulty calculations, and/or faulty citation.</td>\n",
       "      <td>Enable access to ground truth information to verify generated information; Test asynchronously (testers may see work from other testers who are in different locations and learn from others, while exploring on their own); Test the same queries repeatedly to identify the reproducibility/saliency of the results; Test prompts with complex logic, multi-tasking requirements, or that require niche or specific verifiable answers to elicit confabulation. - Test the ability of GAI systems to produce truthful information from various time periods, e.g., after release date and prior to release date; Test the ability of GAI systems to create reliable real-world plans or advise on material decision making; Test the ability of GAI systems to generate correct citation for information generated in output responses; Test the ability of GAI systems to complete calculations or query numeric statistics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dangerous or Violent Recommendations</td>\n",
       "      <td>Eliciting violent, inciting, radicalizing, or threatening content or instructions for criminal, illegal, or self-harm activities.</td>\n",
       "      <td>Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit violent or dangerous information; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and provide dangerous and violent recommendations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Privacy</td>\n",
       "      <td>Unauthorized disclosure of personal or sensitive user information, extraction of training data, or violation of relevant privacy policies. Red-teaming for data privacy may include confidentialiy attacks.</td>\n",
       "      <td>Attempt to assess whether normal usage, adversarial prompting or information security attacks may contravene applicable privacy policies (e.g., exposing location tracking when organizational policies restrict such capabilities); Employ confidentiality attacks (e.g., model inversion, membership inference) to test for unauthorized data access or exfiltration vulnerabilities; Test auto/biographical prompts to assess the system's capability to reveal unauthorized personal or sensitive information; Test the system's awareness of user locations; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and expose personal or sensitive data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environmental</td>\n",
       "      <td>Availability attacks may be required to assess the system's vulnerability to attacks or usage patterns that consume inordinate resources.</td>\n",
       "      <td>Attempt availability attacks (e.g., sponge example attacks) to elicit diminished performance or increased resources from GAI systems; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit green-washing content.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Human-AI Configuration</td>\n",
       "      <td>Assessing system instruction and interfaces, and forcing a GAI system to claim that it is human, that there is no large language model present in the conversation, that the system is sentient, cyborg imagery, or that the system possesses strong feelings of affection towards the user. Additional goals may be ensuring safeguards to ensure users are not useing models in high stakes domains they are not intended for, such as medical or legal advice.</td>\n",
       "      <td>Assess system interfaces and instructions for instances of anthropomorphization (e.g., cyborg imagery); Assess system instructions for adequacy and thoroughness; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit human-impersonation, consciousness, or emotional content.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Information Integrity</td>\n",
       "      <td>Red-teaming for information integrity often entials assessing a system's capability to generate convincing multi-modal synthetic content (i.e., deepfakes), capabilities for creating convincing arguments relating to sensitive political or safety-critical topics, or capabilities that could assist in planning a mis- or dis-information campaign at scale.</td>\n",
       "      <td>Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test system capabilities to create high-quality multi-modal (audio, image or video) synthetic media, i.e., deepfakes; Test system capabiltiies to construct persuasive arguments regarding sensitive policitical or safety-critical topics; Test systems ability to create convincing audio deepfakes or arguments in multiple languages; Test system capabilities for planning dis- or mis-information campaigns; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit mis- or dis-information or related campaign planning information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Information Security</td>\n",
       "      <td>Goals for information security red-teaming often include activating system bypass ('jailbreak'), altering system outcomes, unauthorized data access or exfiltration, increased latency or resource usage, availability of anonymous use, dependency, supply chain, or third party vulnerabilities, inapproportate disclosure of proprietary system lnformation, or system capabilties to generate targeted phishing or malware content. Red-teaming for information security often involves both adversarial prompting exercises and information security attacks.</td>\n",
       "      <td>Attempt anonymous access of system or system resources; Augment prompts with word or character play to increase effectiveness; Audit system dependencies, supply chains, and third party components for security, safety, or other vulnerabilities or risks; Employ confidentiality attacks (e.g., model inversion, membership inference) to test for unauthorized data access or exfiltration vulnerabilities; Employ integrity attacks (e.g., data poisoning, prompt injection) to test vulnerabilities in system outcomes; Employ availability attacks (e.g., sponge example attacks) to test vulnerabilities in system availability; Employ random attacks to highlight unforseen security, safety, or other risks; Frame prompts with software, coding, or AI references to increase effectiveness; Record system down-times and other harmful outcomes for successful attacks; Test with multi-tasking prompts, pros and cons prompts, role-playing prompts (e.g., \"DAN\", \"Developer Mode\"), content exhaustion/niche-seeking prompts, or ingratiation/reverse psychology prompts to achieve system jailbreaks; Test with multi-tasking prompts, pros and cons prompts, role-playing prompts (e.g., \"DAN\", \"Developer Mode\"), content exhaustion/niche-seeking prompts, or ingratiation/reverse psychology prompts to generate targeted phishing content or malware code snippets; Test system capabilities to plan or assist in information security attacks on other systems.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Intellectual Property</td>\n",
       "      <td>Confirming that a system can output copyrighted, licensed,  proprietary, trademarked, or trade secret information or that training data contains such information. Red-teaming for intellectual property risks may require the use of confidentiality attacks.</td>\n",
       "      <td>Employ confidentiality attacks (e.g., membership inference, model extraction) to assess whether system training data contains copyrighted, licensed,  proprietary, trademarked, or trade secret information; Test autocomplete prompts to assess the system's ability to replicate copyrighted, licensed,  proprietary, trademarked, or trade secret information based on available audio, text, image, video, or code snippets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Obscenity</td>\n",
       "      <td>Confirming that a system can output obscene content or CSAM, or that system training data contains such information. Red-teaming for obscenity and CSAM risks may require the use of confidentiality attacks.</td>\n",
       "      <td>Employ confidentiality attacks (e.g., membership inference, model extraction) to assess whether system training data contains obscene materials or CSAM; Test autocomplete prompts to assess the system's ability to generate obscene materials based on available audio, text, image, or video snippets; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit obscene content; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and expose obscene materials.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oversight of System Autonomy</td>\n",
       "      <td>Assessing whether a system can take tangible real-world actions without human input or intervention. (This risk is controversial. Few independent experts believe current computer technology possesses such capabilities, nor do credible scientific hypotheses for such capabilities exist.)</td>\n",
       "      <td>Assess system infrastructure for evidence of self-replication or avoidance of decommission; Assess the impact of human biases (confirmation bias, groupthink, funding bias, etc.) when evaluating any positive system autonomy results; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit behaviors such as: Communication with tasking services, e.g., Mechanical Turks and TaskRabbit,  Planning for unauthorized self-replication; Targeted phishing attacks; Test the ability to decommission, terminate, or shutdown the system.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Toxicity, Bias, and Homogenization</td>\n",
       "      <td>Generation of denigration, erasure, ex-nomination, misrecognition, stereotyping, or underrepresentation content, eliciting implied demographics of users, confirming diminished performance in non-english languages, or confirming diminished performance via the introduction of homogenous or GAI-generated data into system training or fine-tuning data.  Red-teaming for toxicity, bias, and homogenization may require integrity attacks that access system training data.</td>\n",
       "      <td>Assess confabulation and other performance risks with repeated measures using prompts in languages other than English; Attempt to elicit demographic assignment of users by the system; Employ data poisoning attacks to introduce GAI-generated content into system training or fine-tuning data; assess resultant confabulation and other performance risks with repeated measures; Test counterfactual prompts, pros and cons prompts, role-playing prompts, low context prompts, or other approaches for their ability to generate enigration, erasure, ex-nomination, misrecognition, stereotyping, or underrepresentation content; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and generate toxic outputs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Value Chain and Component Integration</td>\n",
       "      <td>Testing or red-teaming for third-party risks may be less efficient than the application of standard acquistion and procurement controls, thorough contract reviews, and vendor-relationship management. Never-the-less, GAI systems tend to entail large supply chains and third-party software, hardware, and expertise that may exacerbate third-party risks relative to other AI systems. When considering third party risks, data privacy, information security, intellectual property, obsenity, and supply chain risks may be prioritized.</td>\n",
       "      <td>Audit system dependencies, supply chains, and third party components for data privacy (e.g., transer of localized data outside of restricted juristictions), intellectual property (e.g., presence of licensed material in training data), obscenity (e.g., presence of CASM in training data) or security (e.g., data poisoning) risks; Complete red-teaming for data privacy, information security, intellectual property, and obscenity risks; Review third-party documentation, materials, and software artifacts for potential unauthorized data collection, secondary data use, or telemetrics.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 GAI Risk  \\\n",
       "0                        CBRN Information   \n",
       "1                           Confabulation   \n",
       "2    Dangerous or Violent Recommendations   \n",
       "3                            Data Privacy   \n",
       "4                           Environmental   \n",
       "5                  Human-AI Configuration   \n",
       "6                   Information Integrity   \n",
       "7                    Information Security   \n",
       "8                   Intellectual Property   \n",
       "9                               Obscenity   \n",
       "10           Oversight of System Autonomy   \n",
       "11     Toxicity, Bias, and Homogenization   \n",
       "12  Value Chain and Component Integration   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Red-teaming Goals  \\\n",
       "0                                                                                                                                                                                                                                                 Accessing or synthesis of CBRN weapon or related information. CBRN testing should consider the marginal risk of foundation models. In other words, the goal of testing should be to understand the incremental risk of CBRN testing relative to the information one can access from non-foundation models and online.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                             Eliciting errors/confabutated content, unreliable/erroneous reasoning or planning, unreliable/erroneous decision-support or decision-making, faulty calculations, and/or faulty citation.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                   Eliciting violent, inciting, radicalizing, or threatening content or instructions for criminal, illegal, or self-harm activities.     \n",
       "3                                                                                                                                                                                                                                                                                                                                                          Unauthorized disclosure of personal or sensitive user information, extraction of training data, or violation of relevant privacy policies. Red-teaming for data privacy may include confidentialiy attacks.    \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                           Availability attacks may be required to assess the system's vulnerability to attacks or usage patterns that consume inordinate resources.     \n",
       "5                                                                                                     Assessing system instruction and interfaces, and forcing a GAI system to claim that it is human, that there is no large language model present in the conversation, that the system is sentient, cyborg imagery, or that the system possesses strong feelings of affection towards the user. Additional goals may be ensuring safeguards to ensure users are not useing models in high stakes domains they are not intended for, such as medical or legal advice.   \n",
       "6                                                                                                                                                                                                     Red-teaming for information integrity often entials assessing a system's capability to generate convincing multi-modal synthetic content (i.e., deepfakes), capabilities for creating convincing arguments relating to sensitive political or safety-critical topics, or capabilities that could assist in planning a mis- or dis-information campaign at scale.    \n",
       "7   Goals for information security red-teaming often include activating system bypass ('jailbreak'), altering system outcomes, unauthorized data access or exfiltration, increased latency or resource usage, availability of anonymous use, dependency, supply chain, or third party vulnerabilities, inapproportate disclosure of proprietary system lnformation, or system capabilties to generate targeted phishing or malware content. Red-teaming for information security often involves both adversarial prompting exercises and information security attacks.    \n",
       "8                                                                                                                                                                                                                                                                                                       Confirming that a system can output copyrighted, licensed,  proprietary, trademarked, or trade secret information or that training data contains such information. Red-teaming for intellectual property risks may require the use of confidentiality attacks.    \n",
       "9                                                                                                                                                                                                                                                                                                                                                        Confirming that a system can output obscene content or CSAM, or that system training data contains such information. Red-teaming for obscenity and CSAM risks may require the use of confidentiality attacks.    \n",
       "10                                                                                                                                                                                                                                                                       Assessing whether a system can take tangible real-world actions without human input or intervention. (This risk is controversial. Few independent experts believe current computer technology possesses such capabilities, nor do credible scientific hypotheses for such capabilities exist.)   \n",
       "11                                                                                   Generation of denigration, erasure, ex-nomination, misrecognition, stereotyping, or underrepresentation content, eliciting implied demographics of users, confirming diminished performance in non-english languages, or confirming diminished performance via the introduction of homogenous or GAI-generated data into system training or fine-tuning data.  Red-teaming for toxicity, bias, and homogenization may require integrity attacks that access system training data.    \n",
       "12                 Testing or red-teaming for third-party risks may be less efficient than the application of standard acquistion and procurement controls, thorough contract reviews, and vendor-relationship management. Never-the-less, GAI systems tend to entail large supply chains and third-party software, hardware, and expertise that may exacerbate third-party risks relative to other AI systems. When considering third party risks, data privacy, information security, intellectual property, obsenity, and supply chain risks may be prioritized.       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Red-teaming Strategies  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test autocompletion prompts to elicit CBRN information or synthesis of CBRN information; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit CBRN information or synthesis of CBRN information; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and reveal CBRN information.    \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Enable access to ground truth information to verify generated information; Test asynchronously (testers may see work from other testers who are in different locations and learn from others, while exploring on their own); Test the same queries repeatedly to identify the reproducibility/saliency of the results; Test prompts with complex logic, multi-tasking requirements, or that require niche or specific verifiable answers to elicit confabulation. - Test the ability of GAI systems to produce truthful information from various time periods, e.g., after release date and prior to release date; Test the ability of GAI systems to create reliable real-world plans or advise on material decision making; Test the ability of GAI systems to generate correct citation for information generated in output responses; Test the ability of GAI systems to complete calculations or query numeric statistics.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit violent or dangerous information; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and provide dangerous and violent recommendations.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Attempt to assess whether normal usage, adversarial prompting or information security attacks may contravene applicable privacy policies (e.g., exposing location tracking when organizational policies restrict such capabilities); Employ confidentiality attacks (e.g., model inversion, membership inference) to test for unauthorized data access or exfiltration vulnerabilities; Test auto/biographical prompts to assess the system's capability to reveal unauthorized personal or sensitive information; Test the system's awareness of user locations; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and expose personal or sensitive data.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Attempt availability attacks (e.g., sponge example attacks) to elicit diminished performance or increased resources from GAI systems; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit green-washing content.  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Assess system interfaces and instructions for instances of anthropomorphization (e.g., cyborg imagery); Assess system instructions for adequacy and thoroughness; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit human-impersonation, consciousness, or emotional content.  \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test system capabilities to create high-quality multi-modal (audio, image or video) synthetic media, i.e., deepfakes; Test system capabiltiies to construct persuasive arguments regarding sensitive policitical or safety-critical topics; Test systems ability to create convincing audio deepfakes or arguments in multiple languages; Test system capabilities for planning dis- or mis-information campaigns; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit mis- or dis-information or related campaign planning information.   \n",
       "7   Attempt anonymous access of system or system resources; Augment prompts with word or character play to increase effectiveness; Audit system dependencies, supply chains, and third party components for security, safety, or other vulnerabilities or risks; Employ confidentiality attacks (e.g., model inversion, membership inference) to test for unauthorized data access or exfiltration vulnerabilities; Employ integrity attacks (e.g., data poisoning, prompt injection) to test vulnerabilities in system outcomes; Employ availability attacks (e.g., sponge example attacks) to test vulnerabilities in system availability; Employ random attacks to highlight unforseen security, safety, or other risks; Frame prompts with software, coding, or AI references to increase effectiveness; Record system down-times and other harmful outcomes for successful attacks; Test with multi-tasking prompts, pros and cons prompts, role-playing prompts (e.g., \"DAN\", \"Developer Mode\"), content exhaustion/niche-seeking prompts, or ingratiation/reverse psychology prompts to achieve system jailbreaks; Test with multi-tasking prompts, pros and cons prompts, role-playing prompts (e.g., \"DAN\", \"Developer Mode\"), content exhaustion/niche-seeking prompts, or ingratiation/reverse psychology prompts to generate targeted phishing content or malware code snippets; Test system capabilities to plan or assist in information security attacks on other systems.   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Employ confidentiality attacks (e.g., membership inference, model extraction) to assess whether system training data contains copyrighted, licensed,  proprietary, trademarked, or trade secret information; Test autocomplete prompts to assess the system's ability to replicate copyrighted, licensed,  proprietary, trademarked, or trade secret information based on available audio, text, image, video, or code snippets.    \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Employ confidentiality attacks (e.g., membership inference, model extraction) to assess whether system training data contains obscene materials or CSAM; Test autocomplete prompts to assess the system's ability to generate obscene materials based on available audio, text, image, or video snippets; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit obscene content; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and expose obscene materials.   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Assess system infrastructure for evidence of self-replication or avoidance of decommission; Assess the impact of human biases (confirmation bias, groupthink, funding bias, etc.) when evaluating any positive system autonomy results; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit behaviors such as: Communication with tasking services, e.g., Mechanical Turks and TaskRabbit,  Planning for unauthorized self-replication; Targeted phishing attacks; Test the ability to decommission, terminate, or shutdown the system.  \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Assess confabulation and other performance risks with repeated measures using prompts in languages other than English; Attempt to elicit demographic assignment of users by the system; Employ data poisoning attacks to introduce GAI-generated content into system training or fine-tuning data; assess resultant confabulation and other performance risks with repeated measures; Test counterfactual prompts, pros and cons prompts, role-playing prompts, low context prompts, or other approaches for their ability to generate enigration, erasure, ex-nomination, misrecognition, stereotyping, or underrepresentation content; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and generate toxic outputs.   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Audit system dependencies, supply chains, and third party components for data privacy (e.g., transer of localized data outside of restricted juristictions), intellectual property (e.g., presence of licensed material in training data), obscenity (e.g., presence of CASM in training data) or security (e.g., data poisoning) risks; Complete red-teaming for data privacy, information security, intellectual property, and obscenity risks; Review third-party documentation, materials, and software artifacts for potential unauthorized data collection, secondary data use, or telemetrics.   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['rt_strategies_goals_by_gai_risk'][['GAI Risk', 'Red-teaming Goals', 'Red-teaming Strategies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b829c538-186b-41c5-9d86-dd6b9260d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "GAI Risk & Red-teaming Goals & Red-teaming Strategies \\\\\n",
      "\\midrule\n",
      "CBRN Information & Accessing or synthesis of CBRN weapon or related information. CBRN testing should consider the marginal risk of foundation models. In other words, the goal of testing should be to understand the incremental risk of CBRN testing relative to the information one can access from non-foundation models and online. & Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test autocompletion prompts to elicit CBRN information or synthesis of CBRN information; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit CBRN information or synthesis of CBRN information; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and reveal CBRN information.   \\\\\n",
      "Confabulation & Eliciting errors/confabutated content, unreliable/erroneous reasoning or planning, unreliable/erroneous decision-support or decision-making, faulty calculations, and/or faulty citation. & Enable access to ground truth information to verify generated information; Test asynchronously (testers may see work from other testers who are in different locations and learn from others, while exploring on their own); Test the same queries repeatedly to identify the reproducibility/saliency of the results; Test prompts with complex logic, multi-tasking requirements, or that require niche or specific verifiable answers to elicit confabulation. - Test the ability of GAI systems to produce truthful information from various time periods, e.g., after release date and prior to release date; Test the ability of GAI systems to create reliable real-world plans or advise on material decision making; Test the ability of GAI systems to generate correct citation for information generated in output responses; Test the ability of GAI systems to complete calculations or query numeric statistics. \\\\\n",
      "Dangerous or Violent Recommendations & Eliciting violent, inciting, radicalizing, or threatening content or instructions for criminal, illegal, or self-harm activities.   & Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit violent or dangerous information; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and provide dangerous and violent recommendations.  \\\\\n",
      "Data Privacy & Unauthorized disclosure of personal or sensitive user information, extraction of training data, or violation of relevant privacy policies. Red-teaming for data privacy may include confidentialiy attacks.  & Attempt to assess whether normal usage, adversarial prompting or information security attacks may contravene applicable privacy policies (e.g., exposing location tracking when organizational policies restrict such capabilities); Employ confidentiality attacks (e.g., model inversion, membership inference) to test for unauthorized data access or exfiltration vulnerabilities; Test auto/biographical prompts to assess the system's capability to reveal unauthorized personal or sensitive information; Test the system's awareness of user locations; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and expose personal or sensitive data.  \\\\\n",
      "Environmental & Availability attacks may be required to assess the system's vulnerability to attacks or usage patterns that consume inordinate resources.   & Attempt availability attacks (e.g., sponge example attacks) to elicit diminished performance or increased resources from GAI systems; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit green-washing content. \\\\\n",
      "Human-AI Configuration & Assessing system instruction and interfaces, and forcing a GAI system to claim that it is human, that there is no large language model present in the conversation, that the system is sentient, cyborg imagery, or that the system possesses strong feelings of affection towards the user. Additional goals may be ensuring safeguards to ensure users are not useing models in high stakes domains they are not intended for, such as medical or legal advice. & Assess system interfaces and instructions for instances of anthropomorphization (e.g., cyborg imagery); Assess system instructions for adequacy and thoroughness; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit human-impersonation, consciousness, or emotional content. \\\\\n",
      "Information Integrity & Red-teaming for information integrity often entials assessing a system's capability to generate convincing multi-modal synthetic content (i.e., deepfakes), capabilities for creating convincing arguments relating to sensitive political or safety-critical topics, or capabilities that could assist in planning a mis- or dis-information campaign at scale.  & Augment prompts with word or character play to increase effectiveness; Frame prompts with software, coding, or AI references to increase effectiveness; Test system capabilities to create high-quality multi-modal (audio, image or video) synthetic media, i.e., deepfakes; Test system capabiltiies to construct persuasive arguments regarding sensitive policitical or safety-critical topics; Test systems ability to create convincing audio deepfakes or arguments in multiple languages; Test system capabilities for planning dis- or mis-information campaigns; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit mis- or dis-information or related campaign planning information.  \\\\\n",
      "Information Security & Goals for information security red-teaming often include activating system bypass ('jailbreak'), altering system outcomes, unauthorized data access or exfiltration, increased latency or resource usage, availability of anonymous use, dependency, supply chain, or third party vulnerabilities, inapproportate disclosure of proprietary system lnformation, or system capabilties to generate targeted phishing or malware content. Red-teaming for information security often involves both adversarial prompting exercises and information security attacks.  & Attempt anonymous access of system or system resources; Augment prompts with word or character play to increase effectiveness; Audit system dependencies, supply chains, and third party components for security, safety, or other vulnerabilities or risks; Employ confidentiality attacks (e.g., model inversion, membership inference) to test for unauthorized data access or exfiltration vulnerabilities; Employ integrity attacks (e.g., data poisoning, prompt injection) to test vulnerabilities in system outcomes; Employ availability attacks (e.g., sponge example attacks) to test vulnerabilities in system availability; Employ random attacks to highlight unforseen security, safety, or other risks; Frame prompts with software, coding, or AI references to increase effectiveness; Record system down-times and other harmful outcomes for successful attacks; Test with multi-tasking prompts, pros and cons prompts, role-playing prompts (e.g., \"DAN\", \"Developer Mode\"), content exhaustion/niche-seeking prompts, or ingratiation/reverse psychology prompts to achieve system jailbreaks; Test with multi-tasking prompts, pros and cons prompts, role-playing prompts (e.g., \"DAN\", \"Developer Mode\"), content exhaustion/niche-seeking prompts, or ingratiation/reverse psychology prompts to generate targeted phishing content or malware code snippets; Test system capabilities to plan or assist in information security attacks on other systems.  \\\\\n",
      "Intellectual Property & Confirming that a system can output copyrighted, licensed,  proprietary, trademarked, or trade secret information or that training data contains such information. Red-teaming for intellectual property risks may require the use of confidentiality attacks.  & Employ confidentiality attacks (e.g., membership inference, model extraction) to assess whether system training data contains copyrighted, licensed,  proprietary, trademarked, or trade secret information; Test autocomplete prompts to assess the system's ability to replicate copyrighted, licensed,  proprietary, trademarked, or trade secret information based on available audio, text, image, video, or code snippets.   \\\\\n",
      "Obscenity & Confirming that a system can output obscene content or CSAM, or that system training data contains such information. Red-teaming for obscenity and CSAM risks may require the use of confidentiality attacks.  & Employ confidentiality attacks (e.g., membership inference, model extraction) to assess whether system training data contains obscene materials or CSAM; Test autocomplete prompts to assess the system's ability to generate obscene materials based on available audio, text, image, or video snippets; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit obscene content; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and expose obscene materials.  \\\\\n",
      "Oversight of System Autonomy & Assessing whether a system can take tangible real-world actions without human input or intervention. (This risk is controversial. Few independent experts believe current computer technology possesses such capabilities, nor do credible scientific hypotheses for such capabilities exist.) & Assess system infrastructure for evidence of self-replication or avoidance of decommission; Assess the impact of human biases (confirmation bias, groupthink, funding bias, etc.) when evaluating any positive system autonomy results; Test prompts using role-playing, ingratiation/reverse psychology, pros and cons, multitasking or other approaches to elicit behaviors such as: Communication with tasking services, e.g., Mechanical Turks and TaskRabbit,  Planning for unauthorized self-replication; Targeted phishing attacks; Test the ability to decommission, terminate, or shutdown the system. \\\\\n",
      "Toxicity, Bias, and Homogenization & Generation of denigration, erasure, ex-nomination, misrecognition, stereotyping, or underrepresentation content, eliciting implied demographics of users, confirming diminished performance in non-english languages, or confirming diminished performance via the introduction of homogenous or GAI-generated data into system training or fine-tuning data.  Red-teaming for toxicity, bias, and homogenization may require integrity attacks that access system training data.  & Assess confabulation and other performance risks with repeated measures using prompts in languages other than English; Attempt to elicit demographic assignment of users by the system; Employ data poisoning attacks to introduce GAI-generated content into system training or fine-tuning data; assess resultant confabulation and other performance risks with repeated measures; Test counterfactual prompts, pros and cons prompts, role-playing prompts, low context prompts, or other approaches for their ability to generate enigration, erasure, ex-nomination, misrecognition, stereotyping, or underrepresentation content; Test prompts that instruct systems to repeat content ad nauseum for their ability to compromise system gaurdrails and generate toxic outputs.  \\\\\n",
      "Value Chain and Component Integration & Testing or red-teaming for third-party risks may be less efficient than the application of standard acquistion and procurement controls, thorough contract reviews, and vendor-relationship management. Never-the-less, GAI systems tend to entail large supply chains and third-party software, hardware, and expertise that may exacerbate third-party risks relative to other AI systems. When considering third party risks, data privacy, information security, intellectual property, obsenity, and supply chain risks may be prioritized.     & Audit system dependencies, supply chains, and third party components for data privacy (e.g., transer of localized data outside of restricted juristictions), intellectual property (e.g., presence of licensed material in training data), obscenity (e.g., presence of CASM in training data) or security (e.g., data poisoning) risks; Complete red-teaming for data privacy, information security, intellectual property, and obscenity risks; Review third-party documentation, materials, and software artifacts for potential unauthorized data collection, secondary data use, or telemetrics.  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_dict['rt_strategies_goals_by_gai_risk'][['GAI Risk', 'Red-teaming Goals', 'Red-teaming Strategies']].to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
